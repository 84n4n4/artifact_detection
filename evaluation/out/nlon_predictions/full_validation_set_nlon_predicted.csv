V1,doc,target,nlonPrediction
0,### OrientDB Version: 3.0.21,1,1
1,### Java Version: 1.8.0_144,1,1
2,### OS: windows 10,1,1
3,## Expected behavior,1,1
4,## Actual behavior,1,1
5,"> Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
6,"INFO: Windows OS is detected, 262144 limit of open files will be set for the disk cache.",0,1
7,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
8,INFO: 17118322688 B/16325 MB/15 GB of physical memory were detected on machine,0,0
9,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
10,INFO: Detected memory limit for current process is 17118322688 B/16325 MB/15 GB,0,0
11,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
12,INFO: JVM can use maximum 3628MB of heap memory,0,0
13,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
14,INFO: Because OrientDB is running outside a container 12% of memory will be left unallocated according to the setting 'memory.leftToOS' not taking into account heap memory,0,1
15,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
16,"INFO: OrientDB auto-config DISKCACHE=10,737MB (heap=3,628MB os=16,325MB)",0,0
17,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
18,INFO: System is started under an effective user : `test`,0,0
19,"Jun 30, 2019 1:29:32 PM com.orientechnologies.common.log.OLogManager log",0,0
20,INFO: Allocation of 163202 pages.,0,0
21,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
22,"INFO: WAL maximum segment size is set to 6,144 MB",0,0
23,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
24,INFO: Page size for WAL located in Z:\PortableApps\eclipse-oxygen-2\workspace\orientdbtest\.\db\test is set to 4096 bytes.,0,1
25,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
26,WARNING: Storage 'test' was not closed properly. Will try to recover from write ahead log,0,1
27,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
28,INFO: Looking for last checkpoint...,0,1
29,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
30,"INFO: Checkpoints are absent, the restore will start from the beginning.",0,1
31,"Jun 30, 2019 1:29:33 PM com.orientechnologies.common.log.OLogManager log",0,0
32,INFO: Data restore procedure is started.,0,0
33,"Jun 30, 2019 1:29:34 PM com.orientechnologies.common.log.OLogManager log",0,0
34,"WARNING: Record com.orientechnologies.orient.core.storage.impl.local.paginated.wal.cas.OEmptyWALRecord{lsn=OLogSequenceNumber{segment=1, position=18}} will be skipped during data restore",0,0
35,"Jun 30, 2019 1:29:34 PM com.orientechnologies.common.log.OLogManager log",0,0
36,"INFO: 1 operations were processed, current LSN is OLogSequenceNumber{segment=1, position=18} last LSN is OLogSequenceNumber{segment=2, position=18}",0,0
37,"Jun 30, 2019 1:29:34 PM com.orientechnologies.common.log.OLogManager log",0,0
38,WARNING: Non tx operation was used during data modification we will need index rebuild.,0,1
39,"Jun 30, 2019 1:29:36 PM com.orientechnologies.common.log.OLogManager log",0,0
40,"WARNING: Record com.orientechnologies.orient.core.storage.impl.local.paginated.wal.cas.OEmptyWALRecord{lsn=OLogSequenceNumber{segment=2, position=18}} will be skipped during data restore",0,0
41,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
42,INFO: Storage data recover was completed,0,0
43,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
44,"INFO: Storage 'plocal:Z:\PortableApps\eclipse-oxygen-2\workspace\orientdbtest\.\db/test' is opened under OrientDB distribution : 3.0.21 - Veloce (build 1d8b0c01ca8fe12a516bba355681e3ec8b218d1d, branch 3.0.x)",0,0
45,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
46,INFO: $ANSI{green {db=test}} Wait till indexes restore after crash was finished.,0,0
47,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
48,INFO: $ANSI{green {db=test}} Index 'ORole.name' is a durable automatic index and will be added as is without rebuilding,0,0
49,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
50,INFO: $ANSI{green {db=test}} Index 'ORole.name' was added in DB index list,0,0
51,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
52,INFO: $ANSI{green {db=test}} Index 'OUser.name' is a durable automatic index and will be added as is without rebuilding,0,0
53,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
54,INFO: $ANSI{green {db=test}} Index 'OUser.name' was added in DB index list,0,0
55,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
56,INFO: $ANSI{green {db=test}} Index 'dictionary' is a durable non-automatic index and will be added as is without rebuilding,0,0
57,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
58,INFO: $ANSI{green {db=test}} Index 'dictionary' was added in DB index list,0,0
59,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
60,INFO: $ANSI{green {db=test}} Index 'OFunction.name' is a durable automatic index and will be added as is without rebuilding,0,0
61,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
62,INFO: $ANSI{green {db=test}} Index 'OFunction.name' was added in DB index list,0,0
63,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
64,"INFO: $ANSI{green {db=test}} 4 indexes were restored successfully, 0 errors",0,0
65,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
66,INFO: $ANSI{green {db=test}} Indexes restore after crash was finished.,0,0
67,size: 675,0,0
68,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
69,SEVERE: $ANSI{green {db=test}} Magic number verification failed for page `1425` of `pupil.pcl`.,0,1
70,"Jun 30, 2019 1:29:39 PM com.orientechnologies.common.log.OLogManager log",0,0
71,SEVERE: $ANSI{green {db=test}} Magic number verification failed for page `1425` of `pupil.pcl`.,0,1
72,java.lang.Exception,0,0
73,	at com.orientechnologies.orient.core.storage.cache.local.OWOWCache.dumpStackTrace(OWOWCache.java:2306),0,0
74,	at com.orientechnologies.orient.core.storage.cache.local.OWOWCache.verifyMagicAndChecksum(OWOWCache.java:2264),0,0
75,	at com.orientechnologies.orient.core.storage.cache.local.OWOWCache.loadFileContent(OWOWCache.java:2164),0,0
76,	at com.orientechnologies.orient.core.storage.cache.local.OWOWCache.load(OWOWCache.java:1137),0,0
77,	at com.orientechnologies.orient.core.storage.cache.chm.AsyncReadCache.lambda$doLoad$0(AsyncReadCache.java:150),0,0
78,	at java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1853),0,0
79,	at com.orientechnologies.orient.core.storage.cache.chm.AsyncReadCache.doLoad(AsyncReadCache.java:147),0,0
80,	at com.orientechnologies.orient.core.storage.cache.chm.AsyncReadCache.loadForRead(AsyncReadCache.java:115),0,0
81,	at com.orientechnologies.orient.core.storage.impl.local.paginated.atomicoperations.OAtomicOperation.loadPageForWrite(OAtomicOperation.java:111),0,0
82,	at com.orientechnologies.orient.core.storage.impl.local.paginated.base.ODurableComponent.loadPageForWrite(ODurableComponent.java:129),0,0
83,	at com.orientechnologies.orient.core.storage.cluster.v1.OPaginatedClusterV1.addEntry(OPaginatedClusterV1.java:1720),0,0
84,	at com.orientechnologies.orient.core.storage.cluster.v1.OPaginatedClusterV1.createRecord(OPaginatedClusterV1.java:502),0,0
85,	at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.doCreateRecord(OAbstractPaginatedStorage.java:4547),0,0
86,	at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.commitEntry(OAbstractPaginatedStorage.java:5133),0,0
87,	at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.commit(OAbstractPaginatedStorage.java:2161),0,0
88,	at com.orientechnologies.orient.core.storage.impl.local.OAbstractPaginatedStorage.commit(OAbstractPaginatedStorage.java:1993),0,0
89,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentAbstract.internalCommit(ODatabaseDocumentAbstract.java:2732),0,0
90,	at com.orientechnologies.orient.core.storage.impl.local.OMicroTransaction.doCommit(OMicroTransaction.java:363),0,0
91,	at com.orientechnologies.orient.core.storage.impl.local.OMicroTransaction.commit(OMicroTransaction.java:166),0,0
92,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentEmbedded.endMicroTransaction(ODatabaseDocumentEmbedded.java:799),0,0
93,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentEmbedded.executeSaveRecord(ODatabaseDocumentEmbedded.java:789),0,0
94,	at com.orientechnologies.orient.core.tx.OTransactionNoTx.saveNew(OTransactionNoTx.java:244),0,0
95,	at com.orientechnologies.orient.core.tx.OTransactionNoTx.saveRecord(OTransactionNoTx.java:174),0,0
96,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentAbstract.saveInternal(ODatabaseDocumentAbstract.java:2099),0,0
97,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentAbstract.save(ODatabaseDocumentAbstract.java:2064),0,0
98,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentAbstract.save(ODatabaseDocumentAbstract.java:85),0,0
99,	at com.orientechnologies.orient.core.record.impl.ODocument.save(ODocument.java:2169),0,0
100,	at com.orientechnologies.orient.core.record.impl.ODocument.save(ODocument.java:2160),0,0
101,	at com.orientechnologies.orient.core.record.impl.ODocument.save(ODocument.java:118),0,0
102,	at test.Test.main(Test.java:34),0,0
103,## Steps to reproduce,1,1
104,> 	public static void main(String[] args),0,0
105,	{,0,0
106,"		try (OrientDB odb = new OrientDB(""""embedded:./db"""", OrientDBConfig.defaultConfig()))",0,0
107,		{,0,0
108,"		    odb.createIfNotExists(""""test"""", ODatabaseType.PLOCAL); 	",0,0
109,"		    ODatabaseSession db = odb.open(""""test"""", """"admin"""", """"admin"""");",0,0
110,"		    db.getMetadata().getSchema().getOrCreateClass(""""pupil"""");",0,0
111,"		    long size = db.countClass(""""pupil"""");",0,0
112,"		    System.out.println(""""size: """"+size);",0,0
113,		    long t = System.currentTimeMillis();,0,0
114,		    db.declareIntent(new OIntentMassiveInsert());,0,0
115,		    for (int i=0; i<1000000; i++),0,0
116,		    {,0,0
117,"			    OElement doc = db.newElement(""""pupil"""");",0,0
118,"			    doc.setProperty(""""id"""",size+i);",0,0
119,"			    doc.setProperty(""""json"""", randomString());",0,0
120,			    doc.save();,0,0
121,			    if (i % 100 == 0),0,0
122,			    {,0,0
123,			    	System.out.println(System.currentTimeMillis()-t);,0,0
124,			    	t = System.currentTimeMillis();,0,0
125,			    	db.commit();,0,0
126,			    },0,0
127,		    },0,0
128,		},0,0
129,	},0,0
130,force stop the JVM while the program is running.,1,1
131,then restart,1,1
132,"The list, currently, is created via the CategoryDaoImpl.readActiveSubCategoriesByCategory(..) method. This method queries the database via the defaultParentCategory, which possibly misses additional categories that are associated via CategoryXrefImpl, but not via the defaultParentCategory. This is rare, but possible. Also, since ordering is described in CategoryXrefImpl, this query does not take advantage of the proper ordering of subcategories.",1,1
133,An enhancement/fix would be to alter the query to use the category xref table instead.,1,1
134,as found by @virendrachaudhary06 in this comment: https://github.com/intuit/karate/issues/206#issuecomment-340235669,1,1
135,version:redisson-2.2.9,1,0
136,exception:,1,1
137,Caused by: java.lang.NullPointerException,0,0
138,at com.simontuffs.onejar.OneJarFile.getInputStream(OneJarFile.java:116),0,0
139,at com.simontuffs.onejar.OneJarURLConnection.getInputStream(OneJarURLConnection.java:51),0,0
140,at java.net.URL.openStream(URL.java:1037),0,0
141,at org.redisson.Version.logVersion(Version.java:35),0,0
142,at org.redisson.connection.MasterSlaveConnectionManager.<init>(MasterSlaveConnectionManager.java:139),0,0
143,at org.redisson.cluster.ClusterConnectionManager.<init>(ClusterConnectionManager.java:65),0,0
144,at org.redisson.Redisson.<init>(Redisson.java:100),0,0
145,at org.redisson.RedissonExt.create(RedissonExt.java:82),0,0
146,... 60 more,0,0
147,**org.redisson.Version.java**,0,0
148,should catch Exception instead of IOException,1,1
149,`MongoRepositoriesAutoConfiguration` should be after `MongoDataAutoConfiguration` not `MongoAutoConfiguration` otherwise it goes and creates a bunch of beans that `MongoDataAutoConfiguration` want to create itself (like the `MongoMapperContext`).,1,1
150,This should be similar to memcmp() or strcmp() as described in the java-doc.,1,1
151,"This is because the [ByteBufUtil.compare(ByteBuf, ByteBuf)](https://github.com/netty/netty/blob/4.1/buffer/src/main/java/io/netty/buffer/ByteBufUtil.java#L226) compare the `ByteBuf`s as integers and not raw bytes.",1,1
152,```,0,0
153,Sample Code,1,1
154,========,0,0
155,public static void main(String[] args) {,0,0
156,"    ByteBuf buf1 = Unpooled.wrappedBuffer(""""1234"""".getBytes()).order(ByteOrder.LITTLE_ENDIAN);",0,0
157,"    ByteBuf buf2 = Unpooled.wrappedBuffer(""""4321"""".getBytes()).order(ByteOrder.LITTLE_ENDIAN);",0,0
158,"    System.out.println(""""\""""1234\"""".compareTo(\""""4321\"""") = """" + buf1.compareTo(buf2));",0,0
159,"    buf1 = Unpooled.wrappedBuffer(""""1234"""".getBytes()).order(ByteOrder.BIG_ENDIAN);",0,0
160,"    buf2 = Unpooled.wrappedBuffer(""""4321"""".getBytes()).order(ByteOrder.BIG_ENDIAN);",0,0
161,"    System.out.println(""""\""""1234\"""".compareTo(\""""4321\"""") = """" + buf1.compareTo(buf2));",0,0
162,},0,0
163,Output,1,0
164,=====,0,0
165,"""""1234"""".compareTo(""""4321"""") = 1",0,0
166,"""""1234"""".compareTo(""""4321"""") = -1",0,0
167,```,0,0
168,"My app has no field named """"loadFactor"""" - I assume it's some internal MapDB error?",1,1
169,.RuntimeException: Could not set field value: loadFactor - class java.util.LinkedHashMap,0,0
170,at org.mapdb.SerializerPojo$FieldInfo.<init>(SerializerPojo.java:212),0,0
171,It isn't happening on all uses of my Map - not sure what the factor is at this point.  Looking for suggestions on how to track it down.,1,1
172,The retry logic to try and start a river should also handle index missing case if it has not propagated yet.,1,1
173,"I'm using Netty WebSockets with HTTPS. When performing the handshake, the header field `sec-websocket-origin` is set to a value starting with `http://`, which looks weird.",1,1
174,There is nothing about `sec-websocket-origin` in the RFC.,1,1
175,"The string `http` is set inconditionnally in `io.netty.handler.codec.http.websocketx.WebSocketClientHandshaker13`, line 165.",1,1
176,I'm using Netty-4.1.0.CR7.,1,1
177,See https://github.com/spring-projects/spring-boot/issues/9128#issuecomment-358980565 (second paragraph) for the original discussion.,1,1
178,"In short: the runtime classpath should have application classes from `BOOT-INF/classes` before libraries taken from `BOOT-INF/lib`. This would match the observed behaviour of Eclipse, Maven, Surefire, etc.",1,1
179,The current implementation of the `Repackager` respects that order but without any guarantee: it is more because of the current implementation rather than by specification. There is also no test case to assert this order is respected.,1,1
180,"While using the method `OrientBaseGraph.addEdge(Object, Vertex, Vertex, String)` I found some issues trying to define the class name parameter. Looking into the method's implementation it is possible to see that the first part of the method parses the `id` parameter considering the following notation: `class:ClassName,cluster:ClusterName`. Although, as soon as the first part finishes a new parser is executed which generates an invalid class name. The following JUnit test illustrates the problem:",1,1
181,``` java,0,0
182,import org.junit.After;,0,0
183,import org.junit.Before;,0,0
184,import org.junit.Test;,0,0
185,import com.tinkerpop.blueprints.impls.orient.OrientEdgeType;,0,0
186,import com.tinkerpop.blueprints.impls.orient.OrientGraph;,0,0
187,import com.tinkerpop.blueprints.impls.orient.OrientGraphFactory;,0,0
188,import com.tinkerpop.blueprints.impls.orient.OrientGraphNoTx;,0,0
189,import com.tinkerpop.blueprints.impls.orient.OrientVertex;,0,0
190,import com.tinkerpop.blueprints.impls.orient.OrientVertexType;,0,0
191,public class OrientGraphTest {,0,0
192,private OrientGraphNoTx graphDbNoTx;,0,0
193,private OrientGraph graphDbTx;,0,0
194,@Before,0,0
195,public void setupDb() {,0,0
196,"        OrientGraphFactory orientGraphFactory = new OrientGraphFactory(""""memory:testdb"""");",0,0
197,this.graphDbNoTx = orientGraphFactory.getNoTx();,0,0
198,this.graphDbTx = orientGraphFactory.getTx();,0,0
199,},0,0
200,@After,0,0
201,public void closeDatabase() {,0,0
202,this.graphDbTx.drop();,0,0
203,},0,0
204,@Test,0,0
205,public void shouldAddVertexAndEdgeInTheSameCluster() {,0,0
206,"        OrientVertexType deviceVertex = this.graphDbNoTx.createVertexType(""""Device"""");",0,0
207,"        OrientEdgeType edgeType = this.graphDbNoTx.createEdgeType(""""Link"""");",0,0
208,"        edgeType.addCluster(""""Links"""");",0,0
209,"        OrientVertex dev1 = this.graphDbTx.addVertex(""""Device"""");",0,0
210,"        OrientVertex dev2 = this.graphDbTx.addVertex(""""Device"""");",0,0
211,"        this.graphDbTx.addEdge(""""class:Link,cluster:Links"""", dev1, dev2, null);",0,0
212,},0,0
213,},0,0
214,```,0,0
215,In the end the following exception is thrown:,1,1
216,``` java,0,0
217,java.lang.IllegalArgumentException: Invalid field name 'out_Link%2Ccluster%3ALinks'. Character '%' is invalid,0,0
218,at com.orientechnologies.orient.core.record.impl.ODocument.checkFieldName(ODocument.java:1668),0,0
219,at com.orientechnologies.orient.core.record.impl.ODocument.field(ODocument.java:761),0,0
220,at com.orientechnologies.orient.core.record.impl.ODocument.field(ODocument.java:673),0,0
221,at com.tinkerpop.blueprints.impls.orient.OrientVertex.createLink(OrientVertex.java:150),0,0
222,at com.tinkerpop.blueprints.impls.orient.OrientVertex.addEdge(OrientVertex.java:708),0,0
223,at com.tinkerpop.blueprints.impls.orient.OrientBaseGraph.addEdge(OrientBaseGraph.java:527),0,0
224,at br.ind.datacom.provisioning.orientdb.cluster.OrientGraphTest.shouldAddVertexAndEdgeInTheSameCluster(OrientGraphTest.java:41),0,0
225,...,0,0
226,```,0,0
227,In Netty.4.0.24.final.,1,1
228,"In class io.netty.util.Recycler, there's a DEFAULT_MAX_CAPACITY variable to constrain the size of the stack in Recycler. From INITIAL_CAPACITY, whenever the stack is full, it's size doubled until hitting the DEFAULT_MAX_CAPACITY limit(Line 341 in Netty.4.0.24.final). ",1,1
229,![image](https://cloud.githubusercontent.com/assets/1115061/5156597/45b7fa9a-730a-11e4-89aa-bb1f87c47428.png),0,0
230,"As you can see in the image above, stack size is constrained by maxCapacity. And if the size > maxCapacity, this check will fail forever, beacuse the check use """"if (size == maxCapacity)"""" rather than """"if (size > maxCapacity)"""".  And there's a way to set size bigger than maxCapacity.",1,1
231,"In class WeakOrderQueue which is an inner class in Recycler, there's a method called """"transfer"""" which can also double the stack size in Recycler, but there's no check to ensure the stack size not exceed DEFAULT_MAX_CAPACITY limit(Line 218 in Netty.4.0.24.final) like the one mentioned before. ",1,1
232,![image](https://cloud.githubusercontent.com/assets/1115061/5156598/5a17c01a-730a-11e4-873b-1e65ee539db3.png),0,0
233,"In the image above, variable """"to"""" is a stack in Recycler and count is resources's quantity recycled by other thread rather than the Recycler's owner. If there's no enough space for those resources to be recycled, the stack's size will be doubled. I think there should have a check for the stack size here. And whenever the stack size greater than maxCapacity, it can grow infinitely.",1,1
234,"The NPE was triggered when calling the constructor of `ExtractParameterRefactoring`, when the workspace is just opened and no file has been successfully parsed and typechecked by the parse controller.",1,1
235,"When upgrading from 1.x to 2.0, a field that has only a `search_analyzer` specified will throw an exception and prevent the node from starting.  Really, the field does have an `index_analyzer`, set to `default`.  We should be able to migrate this mapping to a 2.0 compatible version.",1,1
236,Relates to #14313,1,1
237,"The incorrect result can be seen in the Interactive Calculator example (actions/tools/Expr.g4) in chapter 10 of the ANTLR4 book, page 181, in which parenthesized expressions always yield 0. ",1,1
238,"When a rule invokes itself recursively, and no label is used, incorrect code is generated when an action references either a variable returned by the recursive call, or any of the subexpression's predefined attributes `text`, `start`, `stop`, or `ctx`. The generated code refers to the current rule's context;  instead it should refer to the child's context. In the calculator example, `$e.v` incorrectly accesses `_localctx.v` (the field where the current rule should put its result, which is initially 0 if numeric or null if a reference type). Thus, the example action assigns the uninitialized field to itself. Instead it should access `_localctx.e.v` (the result from the recursive invocation).",1,1
239,"The problem does not occur when the grammar assigns a label renaming the self-invocation - for example, it would be ok if changed to `'(' ee=e ')' {$v = $ee.v;} ;`    ",1,1
240,Test `testInstallNpmsThenUninstallOneDependency` in class `InstallUninstallNPMPluginUITest` fails randomly with the following exception:,1,1
241,```,0,0
242,IResourceDescription in index must not be an instance of ResourceDescriptionWithoutModuleUserData but it was. URI: file:/var/lib/build/workspace/n4js-extended-nightly/n4js-n4/tests/com.enfore.n4js.ui.tests/target/work/data/.metadata/.plugins/org.eclipse.n4js.external.libraries/.n4npm/node_modules/lodash/fp/matches.js,0,1
243,IResourceDescription in index must not be an instance of ResourceDescriptionWithoutModuleUserData but it was. URI: file:/var/lib/build/workspace/n4js-extended-nightly/n4js-n4/tests/com.enfore.n4js.ui.tests/target/work/data/.metadata/.plugins/org.eclipse.n4js.external.libraries/.n4npm/node_modules/lodash/bind.js,0,1
244,[...],0,0
245,	at org.junit.Assert.fail(Assert.java:88),0,0
246,	at org.junit.Assert.assertTrue(Assert.java:41),0,0
247,	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.assertXtextIndexIsValid(AbstractBuilderTest.java:274),0,0
248,	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.waitForAutoBuild(AbstractBuilderTest.java:204),0,0
249,	at org.eclipse.n4js.tests.builder.AbstractBuilderTest.waitForAutoBuild(AbstractBuilderTest.java:197),0,0
250,	at com.enfore.n4js.tests.externalPackages.InstallUninstallNPMPluginUITest.testInstallNpmsThenUninstallOneDependency(InstallUninstallNPMPluginUITest.java:184),0,0
251,```,0,0
252,For sample builds showing this failure see internal Jenkins build server.,1,1
253,I'm using Spring OAuth 2.0.10.,1,1
254,I have an OAuth Application Client.,1,1
255,"When my access token (AT) expires, Spring OAuth uses the refresh token (RT) to get a new AT from the Authorization Server (AS).",1,1
256,"Problem is if the AS returns a new RT along the new AT, Spring OAuth doesn't pick the new RT and continues using the old RT.",1,1
257,"So on next refresh, I'll get an error.",1,1
258,This is due to https://github.com/spring-projects/spring-security-oauth/blob/b055772adbb9c10497b1077a0480bf2c2649fb04/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/client/token/AccessTokenProviderChain.java#L166.,1,1
259,It should check if there's a RT in the AS response.,1,1
260,"If no, just keep using the old RT. If yes, use the new RT.",1,1
261,"In my scenario, here's the request to the token endpoint :  ",1,1
262,```,0,0
263,POST /oidc/oauth2/token HTTP/1.1,0,0
264,grant_type=refresh_token&refresh_token=90a6e10e2801925583b69ba076c195,0,0
265,```,0,0
266,And the response :,1,1
267,```,0,0
268,{,0,0
269,"   """"access_token"""":""""b6f54d7326354cdfb12227c96b6894a"""",",0,0
270,"   """"token_type"""":""""Bearer"""",",0,0
271,"   """"expires_in"""":3600,",0,0
272,"   """"scope"""":""""openid hello.say"""",",0,0
273,"   """"refresh_token"""":""""e2f9d5d05ed793d2b096a59dcde10e2"""",",0,0
274,"   """"id_token"""":""""eyJhbGciOiJSUzI1NiJ9.eyJwcmVmZXJyZWRfdXNlcm5hbWUiOiJhbGljZSIsInN1YiI6IkNHUjBXTEpaNFdEb1p6ZXExM3h3UXciLCJpYXQiOjE0NzAyOTUxNDgsImV4cCI6MTQ3MDI5ODc0NywiaXNzIjoiYWNjb3VudHMudGFsZW5kLmNvbSIsImdpdmVuX25hbWUiOiJhbGljZSIsImZhbWlseV9uYW1lIjoiYWxpY2UiLCJlbWFpbCI6ImFsaWNlQGdtYWlsLmNvbSIsIm5hbWUiOiJhbGljZSBhbGljZSIsImF1ZCI6IkRCUW91c1N5OFpLNEFBIiwiYXpwIjoiREJRb3VzU3k4Wks0QUEiLCJhdF9oYXNoIjoiU2pyZkF4N2ozM2VvRWF4Vi1JeXRIQSJ9.XxTitaQ5RO7MKfphbKjb0cErBHLDTimj1UTYkYRN1M_EhDnS6TvSHGoryCwMhQ_yANdWOeqZeX_IUmQu2Wj549d_HpLAqzlzrzc1SAbd0nucjWoH3tcCZ2WsuOLigZvhJZpvyj-v-Z2Ov8usk_-fXAP0e-p-MpvGinQ3op-BJQARq2ktM07hQTs8tcVaekpMrjplu-MlxNmqeKSMOQI2TERFZnQRfIYFTQvbCm7hxIs1YJoHnFAh2R_TA_14AJYMBRKXI1yi_EvdJvBkfh-3b7Dxr4pIRIty6aRcsys_9jqF0y4Wdw9Dq6R3GgWgSgvOuyDxq5rmVaR7jLkSw2HVDw""""",0,0
275,},0,0
276,```,0,0
277,Spring OAuth keeps using the old RT (90a6e10e2801925583b69ba076c195) and not the new one (e2f9d5d05ed793d2b096a59dcde10e2).,1,1
278,Extract from OAuth2 specs :,1,1
279,See https://tools.ietf.org/html/rfc6749#section-6,1,1
280,"> The authorization server MAY issue a new refresh token, in which case the client MUST discard the old refresh token and replace it with the new refresh token.  The authorization server MAY revoke the old refresh token after issuing a new refresh token to the client.  If a new refresh token is issued, the refresh token scope MUST be identical to that of the refresh token included by the client in the request.",1,1
281,"lberki has pushed a fix for [issue 1300](https://github.com/bazelbuild/bazel/issues/1300) in order to fix building on windows related to cr lf woes, but now I am getting a different error:",1,1
282,$ ./compile.sh,0,0
283,```,0,0
284,INFO: You can skip this first step by providing a path to the bazel binary as second argument:,0,1
285,INFO:    ./compile.sh compile /path/to/bazel,0,0
286,🍃  Building Bazel from scratch......,0,1
287,🍃  Building Bazel with Bazel.,0,1
288,.WARNING: C:/temp/bazel.Klhij5XN/out/external/bazel_tools/WORKSPACE:1: Workspace name in C:/temp/bazel.Klhij5XN/out/external/bazel_tools/WORKSPACE (@io_bazel) does not match the name given in the repository's definition (@bazel_tools); this will cause a build error in future versions.,0,1
289,ERROR: C:/bazel/tools/build_rules/genproto.bzl:28:75: syntax error at '\': expected expression.,0,0
290,ERROR: C:/bazel/tools/build_rules/genproto.bzl:28:9: missing else clause in conditional expression or semicolon before if.,0,1
291,ERROR: C:/bazel/src/BUILD:127:1: error loading package 'src/main/protobuf': Extension 'tools/build_rules/genproto.bzl' has errors and referenced by '//src:embedded_tools'.,0,0
292,ERROR: Loading failed; build aborted.,0,1
293,INFO: Elapsed time: 0.931s,0,0
294,```,0,0
295,the commit id is 307dc0f627ca8f535a72beea7ed62196ee5553af,1,1
296,We have a 100 of them in ci.bazel.io.,1,1
297,Beans of two different types are required:,1,1
298,- `org.elasticsearch.client.Client`,0,1
299,- `org.springframework.data.elasticsearch.core.convert.ElasticsearchConverter`,0,1
300,"If either of these is missing, the auto-configuration will fail rather than backing off. ",1,1
301,At the moment Tenant management API specification defines that payload (without any mandatory parameters) is required during tenant creation. The implementation at the moment accepts empty body and adds 'enabled' field in that case. Empty body is also used in getting started examples.,1,1
302,We need to align specification with the implementation and examples.,1,1
303,"http://ci.bazel.io/view/Bazel%20bootstrap%20and%20maintenance/job/Bazel/JAVA_VERSION=1.8,PLATFORM_NAME=windows-x86_64/936/consoleFull",0,0
304,There was 1 failure:,0,1
305,1) testGetTargetPathAbsolute(com.google.devtools.build.lib.rules.repository.RepositoryFunctionTest),0,0
306,java.lang.AssertionError: expected:<A:/b/c> but was:</b/c>,0,0
307,at org.junit.Assert.fail(Assert.java:88),0,0
308,at org.junit.Assert.failNotEquals(Assert.java:743),0,0
309,at org.junit.Assert.assertEquals(Assert.java:118),0,0
310,at org.junit.Assert.assertEquals(Assert.java:144),0,0
311,"According to some of the error message, my guess the culprit is ca99bb71b8120e61a3bbde8e54f1a9488fa0478f ",1,1
312,//cc @laszlocsomor,0,1
313,### Issue description,1,1
314,When trying to download movie with Dash Downloader it fails with error:,1,1
315,"""""Unbounded index for representation: ...""""",1,1
316,"Seems, that issue caused by these part of code in DashDownloader.java class in getSegments method:",1,1
317,```,0,0
318,int segmentCount = index.getSegmentCount(C.TIME_UNSET);,0,0
319,if (segmentCount == DashSegmentIndex.INDEX_UNBOUNDED) {,0,0
320,"    throw new DownloadException(""""Unbounded index for representation: """" + key);",0,0
321,},0,0
322,```,0,0
323,"If `C.TIME_UNSET` is always used as parameter, then BaseSegment code rely on `<SegmentTimeline>` tag in mpd file to get segments count. But there is no `<SegmentTimeline>` tag in specific mpd.",1,1
324,"As a workaround I replaced above code with next lines, and download started successfully:",1,1
325,```,0,0
326,long periodDurationUs = manifest.getPeriodDurationUs(key.periodIndex);,0,0
327,int segmentCount = index.getSegmentCount(periodDurationUs);,0,0
328,if (segmentCount == DashSegmentIndex.INDEX_UNBOUNDED) {,0,0
329,"    throw new DownloadException(""""Unbounded index for representation: """" + key);",0,0
330,},0,0
331,```,0,0
332,But I'm not sure that it is a legit way to fix it and which problems my fix may bring.,1,1
333,### Reproduction steps,1,1
334,Try to download video with the next code:,1,1
335,```,0,0
336,"File downloadFolder = new File(""""/storage/emulated/0/downloaded_movies/"""");",0,0
337,"SimpleCache cache = new SimpleCache(downloadFolder, new NoOpCacheEvictor());",0,0
338,DefaultHttpDataSourceFactory factory = new DefaultHttpDataSourceFactory(userAgent);,0,0
339,"DownloaderConstructorHelper helper = new DownloaderConstructorHelper(cache, factory);",0,0
340,"DashDownloader dashDownloader = new DashDownloader(mpdUri, helper);",0,0
341,dashDownloader.download(new Downloader.ProgressListener() {,0,0
342,@Override,0,0
343,"    public void onDownloadProgress(Downloader downloader, float downloadPercentage, long downloadedBytes) {",0,0
344,...,0,0
345,},0,0
346,});,0,0
347,```,0,0
348,### Link to test content,1,1
349,https://media.axprod.net/TestVectors/v7-Clear/Manifest_1080p.mpd,0,0
350,### Version of ExoPlayer being used,1,1
351,2.6.1,0,0
352,### Device(s) and version(s) of Android being used,1,1
353,Not a device specific. I used Nexus 9 Android 7.1.1,1,1
354,### A full bug report captured from the device,1,1
355,Bug report sent by email.,1,1
356,"With #4730 the `Server` header is meant to be disabled by default, but this only works when SSL is not used. Given that disabling the server header is primarily for security reasons, having it work with SSL is pretty essential.",1,1
357,This is because the HTTPS and HTTP connector factories in `JettyEmbeddedServletContainerFactory` don't configure the `HttpConfiguration` in the same way.,1,1
358,Tested with Spring Boot `1.4.2.RELEASE` with the default Jetty version (9.3.14),1,1
359,class：org.redisson.spring.data.connection.RedissonConnection.java,0,0
360,code line：882,1,0
361,code segment：,1,0
362,"<T> T write(byte[] key, Codec codec, RedisCommand<?> command, Object... params) {",0,0
363,"	RFuture<T> f = executorService.writeAsync(key, codec, command, params);",0,0
364,	indexCommand(command);,0,0
365,	return sync(f);,0,0
366,},0,0
367,bug：return null when not used in pipeline / transaction.,1,1
368,### Expected behavior,1,1
369,not return null when not used in pipeline / transaction.,1,1
370,### Actual behavior,1,1
371,return null when not used in pipeline / transaction.,1,1
372,### Steps to reproduce or test case,1,1
373,"public Boolean setNx(String key, String value, long expireMillis) {",0,0
374,	return stringRedisTemplate.execute(new RedisCallback<Boolean>() {,0,0
375,		@Override,0,0
376,		public Boolean doInRedis(RedisConnection connection) throws DataAccessException {,0,0
377,"			return connection.set(key.getBytes(), value.getBytes(), Expiration.milliseconds(expireMillis),",0,0
378,					SetOption.SET_IF_ABSENT);,0,0
379,		},0,0
380,"	}, true);",0,0
381,},0,0
382,### Redis version,1,1
383,Redis-x64-3.0.500,1,0
384,### Redisson version,1,1
385,3.11.1,0,0
386,### Redisson configuration,1,1
387,Trying to set a negative `default` or `lowerBound` value in an elkm file raises an error.,1,1
388,The used grammar rule is `('default' '=' defaultValue=XExpression)?`.,1,1
389,"Hi,",1,1
390,recently the following tests started to fail sporadically:,1,1
391,- `LogFileWebEndpointAutoConfigurationTests.logFileWebEndpointIsAutoConfiguredWhenExternalFileIsSet `,0,1
392,- `DiskSpaceHealthContributorAutoConfigurationTests.runWhenPathDoesNotExistShouldCreateIndicator `,0,1
393,Both seem to be throwing similar errors like this:,1,1
394,```,0,0
395,Caused by: org.springframework.core.convert.ConversionFailedException: Failed to convert from type [java.lang.String] to type [java.io.File] for value 'external.log'; nested exception is java.lang.IllegalStateException: Illegal access: this web application instance has been stopped already. Could not load [external.log]. The following stack trace is thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access.,0,0
396,	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:47),0,0
397,	at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:191),0,0
398,	at org.springframework.boot.context.properties.bind.BindConverter$CompositeConversionService.convert(BindConverter.java:170),0,0
399,	at org.springframework.boot.context.properties.bind.BindConverter.convert(BindConverter.java:96),0,0
400,	at org.springframework.boot.context.properties.bind.BindConverter.convert(BindConverter.java:88),0,0
401,	at org.springframework.boot.context.properties.bind.Binder.bindProperty(Binder.java:434),0,0
402,	at org.springframework.boot.context.properties.bind.Binder.bindObject(Binder.java:379),0,0
403,	at org.springframework.boot.context.properties.bind.Binder.bind(Binder.java:319),0,0
404,	... 142 more,0,0
405,Caused by: java.lang.IllegalStateException: Illegal access: this web application instance has been stopped already. Could not load [external.log]. The following stack trace is thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access.,0,1
406,	at org.apache.catalina.loader.WebappClassLoaderBase.checkStateForResourceLoading(WebappClassLoaderBase.java:1385),0,0
407,	at org.apache.catalina.loader.WebappClassLoaderBase.getResource(WebappClassLoaderBase.java:1038),0,0
408,	at org.springframework.core.io.ClassPathResource.resolveURL(ClassPathResource.java:155),0,0
409,	at org.springframework.core.io.ClassPathResource.exists(ClassPathResource.java:142),0,0
410,	at org.springframework.boot.convert.StringToFileConverter.convert(StringToFileConverter.java:48),0,0
411,	at org.springframework.boot.convert.StringToFileConverter.convert(StringToFileConverter.java:34),0,0
412,	at org.springframework.core.convert.support.GenericConversionService$ConverterAdapter.convert(GenericConversionService.java:385),0,0
413,	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:41),0,0
414,```,0,0
415,"I tried fixing it directly, but I can't see what's going wrong in these cases.",1,1
416,"Cheers,",1,1
417,Christoph,1,0
418,Backport of gh-25110,1,1
419,In the estimation request there should there is an incorrect assumption that there is a fulfillmentoption associated with the fulfillment group.,1,1
420,"In order to finally lay `--incompatible_do_not_split_linking_cmdline` to rest, we need to make some changes to `unix_cc_configure.bzl` which are not backward compatible. Therefore, we need to hide that behind a flag somehow.",1,1
421,"One approach to do so is to expose Starlark incompatible flags to repository functions. However, when such a flag is changed, Starlark repositories are not invalidated and not rebuilt. (note that incorrectness of this pattern already exists at HEAD, because Starlark repository functions, well, depend on Starlark semantics)",1,1
422,This blocks at least:,1,1
423,https://github.com/bazelbuild/bazel/issues/10327,0,1
424,https://github.com/bazelbuild/bazel/issues/9254,0,1
425,"Creating a new project will create a folder that’s literally called `defaultSourceFolder`. That’s a bit silly, it should just be `source`.",1,1
426,"Possibly introduced in c99726aad5a161d205d4988648041501a1f24781. That commit seems to indicate that a resource folder would similarly be called `defaultResourceFolder`, but I haven’t tested that.",1,1
427,"I have accidently created an index with name """"."""" (dot). It was created without any problems. Tried to delete it and elastic did deleted whole my data on whole cluster.",1,1
428,before 4.0.0.CR3 I do this with this code:,1,1
429,```,0,0
430,void broadcast(byte[] data) {,0,0
431,ByteBuf msg = Unpooled.wrappedBuffer(data);,0,0
432,for (Channel ch : channels) {,0,0
433,ch.write(msg);,0,0
434,},0,0
435,},0,0
436,```,0,0
437,with CR3:,1,1
438,```,0,0
439,void broadcast(byte[] data) {,0,0
440,ByteBuf msg = Unpooled.wrappedBuffer(data);,0,0
441,for (Channel ch : channels) {,0,0
442,msg.retain();,0,0
443,ch.write(msg);,0,0
444,},0,0
445,},0,0
446,```,0,0
447,"after upgrade to CR5, the code not work again, seems like netty consume/copy(?) the ByteBuf in a asynchronization way now. And I change my code to:",1,1
448,```,0,0
449,void broadcast(byte[] data) {,0,0
450,ByteBuf msg = Unpooled.wrappedBuffer(data);,0,0
451,for (Channel ch : channels) {,0,0
452,msg.retain();,0,0
453,ch.write(msg.slice());,0,0
454,},0,0
455,},0,0
456,```,0,0
457,"I don't know this is the best way to do. I looked the netty-example project, the examples are all Request-Response. It would be great to add example to demonstrate the offical way to do Request->Broadcast.(e.g. chatting room)",1,1
458,"An extension that is applied to the test class as well to a test method therein gets called twice. As far as I can tell, this behavior was different in the alpha version.",1,1
459,"In my scenario this had undesired consequences and came as a surprise (I expected it to be called once), so I was initially sure it was a bug. After thinking about it for a while I'm not so sure any more. Maybe there is a use case for this?",1,1
460,"More abstract this begs the question of the extension semantics. Does it mean """"call this extension at the implemented extension points"""" (then repeated calls make sense) or does it mean """"activate this extension for the implemented extension points"""" (in which case it should be idempotent).",1,1
461,## Example,1,1
462,``` java,0,0
463,public class DoubleCallback implements BeforeTestExecutionCallback {,0,0
464,@Override,0,0
465,public void beforeTestExecution(TestExtensionContext context) throws Exception {,0,0
466,"        System.out.println(""""Before """" + context.getDisplayName());",0,0
467,},0,0
468,},0,0
469,@ExtendWith(DoubleCallback.class),0,0
470,class DoubleCallbackTest {,0,0
471,@Test,0,0
472,@ExtendWith(DoubleCallback.class),0,0
473,void test() { },0,0
474,},0,0
475,```,0,0
476,Output:,1,1
477,```,0,0
478,Before test(),0,1
479,Before test(),0,1
480,```,0,0
481,## Deliverables,1,1
482,- [x] Add tests for the previous behavior.,1,1
483,- [x] Fix the regression.,1,1
484,- [x] Document semantics regarding parent and child extension contexts in the User Guide.,1,1
485,Sample code :,1,1
486,```,0,0
487,OPartitionedDatabasePoolFactory poolFactory = new OPartitionedDatabasePoolFactory();,0,0
488,"    OPartitionedDatabasePool pool = poolFactory.get(""""plocal:testdb"""", """"administrator"""", """"administrator"""");",0,0
489,ODatabaseDocumentTx db = pool.acquire();,0,0
490,db.close();,0,0
491,pool.close();,0,0
492,```,0,0
493,"After closing the pool, in the later stage of application; getting the pool from the same factory and trying to acquire a new connection reports """"Pool is closed""""",1,1
494,```,0,0
495,java.lang.IllegalStateException: Pool is closed,0,0
496,at com.orientechnologies.orient.core.db.OPartitionedDatabasePool.checkForClose(OPartitionedDatabasePool.java:373),0,0
497,at com.orientechnologies.orient.core.db.OPartitionedDatabasePool.acquire(OPartitionedDatabasePool.java:238),0,0
498,```,0,0
499,"The OPartitionedDatabasePoolFactory retains the pool instance and returns the same, which was closed, as PoolIdentity is same.",1,1
500,### Expected behavior,1,1
501,"`Mono.error(new IllegalStateException(""""boom"""")).log(""""foo"""", FINE)` logs at DEBUG level with SLF4J.",1,1
502,### Actual behavior,1,1
503,It always logs at ERROR level.,1,1
504,### Steps to reproduce,1,1
505,```java,0,0
506,"Mono.error(new IllegalStateException(""""boom""""))",0,0
507,"		    .log(""""foo"""", Level.FINEST)",0,0
508,"		    .subscribe(v -> {}, e -> {});",0,0
509,```,0,0
510,>,0,0
511,```,0,0
512,20:29:11.251 [main] ERROR foo - onError(java.lang.IllegalStateException: boom),0,0
513,20:29:11.258 [main] ERROR foo -,0,0
514,```,0,0
515,### Reactor Core version,1,1
516,3.1.2,0,0
517,"It looks like the """"Icon"""" from the MetaType model is not working when the component is a factory component. It only shows a """"broken image"""" image.",1,1
518,This problem appears to have been introduced at some point in 1.4.0. It happens with 1.4.0.M1 which uses Tomcat 8.0.32. It does not happen with 1.3.3.RELEASE which also uses Tomcat 8.0.32.,1,1
519,"When an application fails to start, the following two warnings are logged:",1,1
520,```,0,0
521,2016-03-08 10:02:07.076  WARN 42263 --- [ost-startStop-1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [main] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:,0,0
522,sun.misc.Unsafe.park(Native Method),0,0
523,java.util.concurrent.locks.LockSupport.park(LockSupport.java:175),0,0
524,java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429),0,0
525,java.util.concurrent.FutureTask.get(FutureTask.java:191),0,0
526,org.apache.catalina.core.ContainerBase.stopInternal(ContainerBase.java:972),0,0
527,org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:224),0,0
528,org.apache.catalina.core.StandardService.stopInternal(StandardService.java:502),0,0
529,org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:224),0,0
530,org.apache.catalina.core.StandardServer.stopInternal(StandardServer.java:790),0,0
531,org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:224),0,0
532,org.apache.catalina.startup.Tomcat.stop(Tomcat.java:355),0,0
533,org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.stopSilently(TomcatEmbeddedServletContainer.java:194),0,0
534,org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer.start(TomcatEmbeddedServletContainer.java:175),0,0
535,org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.startEmbeddedServletContainer(EmbeddedWebApplicationContext.java:293),0,0
536,org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:141),0,0
537,org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:541),0,0
538,org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:118),0,0
539,org.springframework.boot.SpringApplication.refresh(SpringApplication.java:768),0,0
540,org.springframework.boot.SpringApplication.createAndRefreshContext(SpringApplication.java:362),0,0
541,org.springframework.boot.SpringApplication.run(SpringApplication.java:308),0,0
542,org.springframework.boot.SpringApplication.run(SpringApplication.java:1183),0,0
543,org.springframework.boot.SpringApplication.run(SpringApplication.java:1172),0,0
544,sample.web.staticcontent.SampleWebStaticApplication.main(SampleWebStaticApplication.java:33),0,0
545,sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method),0,0
546,sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),0,0
547,sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),0,0
548,java.lang.reflect.Method.invoke(Method.java:498),0,0
549,org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:54),0,0
550,org.springframework.boot.loader.Launcher.launch(Launcher.java:101),0,0
551,org.springframework.boot.loader.Launcher.launch(Launcher.java:58),0,0
552,org.springframework.boot.loader.WarLauncher.main(WarLauncher.java:59),0,0
553,2016-03-08 10:02:07.076  WARN 42263 --- [ost-startStop-1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [container-0] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:,0,0
554,java.lang.Thread.sleep(Native Method),0,0
555,org.apache.catalina.core.StandardServer.await(StandardServer.java:407),0,0
556,org.springframework.boot.context.embedded.tomcat.TomcatEmbeddedServletContainer$1.run(TomcatEmbeddedServletContainer.java:154),0,0
557,```,0,0
558,We’ve implemented it as `String.toRequestBody()` but I think we might be mistaken here. `to` feels like a conversion; `as` feels like a cast. I’d like to confirm what the precedents are and follow them.,1,1
559,Child of https://github.com/checkstyle/checkstyle/issues/5777,1,1
560,This issue specifically focuses on AvoidStaticImport .,1,1
561,"It looks like `QuartzAutoConfiguration` will perform `DataSource` initialization, irrespective of the job store type. This means that an application with a `DataSource` bean that's using an in-memory job store will still have Quartz's DDL applied to the `DataSource`.",1,1
562,### Issue description,1,1
563,"I'm trying to get AudioFocus behavior: duck (lower volume) on notifications and pause on incoming call (and play after call end). When i look at the code https://github.com/google/ExoPlayer/blob/release-v2/library/core/src/main/java/com/google/android/exoplayer2/audio/AudioFocusManager.java#L419 default ExoPlayer implementation should be working like this (or maybe i don't understand it well). But unfortunetely - on incoming call volume is down to 0, but playback doesn't stop.",1,1
564,Interestingly enough. `CONTENT_TYPE_SPEECH` is not working either. Playback isn't stopped on both - notifications and incoming call.,1,1
565,### Reproduction steps,1,1
566,I set audio attributes like this,1,1
567,```kotlin,0,0
568,setAudioAttributes(AudioAttributes.Builder(),0,0
569,.setContentType(C.CONTENT_TYPE_MUSIC),0,0
570,.setUsage(C.USAGE_MEDIA),0,1
571,"    .build(), true)",0,0
572,```,0,0
573,In logs i can see that `AUDIOFOCUS_LOSS_TRANSIENT` was dispatched. It seems like `PLAYER_COMMAND_WAIT_FOR_CALLBACK` wasn't handled properly.,1,1
574,```,0,0
575,D/AudioManager: dispatching onAudioFocusChange(-2) to android.media.AudioManager@1420c8com.google.android.exoplayer2.audio.AudioFocusManager$AudioFocusListener@d3f1561,0,0
576,D/AudioManager: dispatching onAudioFocusChange(1) to android.media.AudioManager@1420c8com.google.android.exoplayer2.audio.AudioFocusManager$AudioFocusListener@d3f1561,0,0
577,```,0,0
578,EDIT: when i digged deeper i found that on `SimpleExoPlayer` `ComponentListener` to `PlayerCommand` is ignoring `PLAYER_COMMAND_WAIT_FOR_CALLBACK` completely,1,1
579,```java,0,0
580,private void updatePlayWhenReady(,0,0
581,"      boolean playWhenReady, @AudioFocusManager.PlayerCommand int playerCommand) {",0,0
582,player.setPlayWhenReady(,0,0
583,"        playWhenReady && playerCommand != AudioFocusManager.PLAYER_COMMAND_DO_NOT_PLAY,",0,0
584,playerCommand != AudioFocusManager.PLAYER_COMMAND_PLAY_WHEN_READY);,0,0
585,},0,0
586,```,0,0
587,### Version of ExoPlayer being used,1,1
588,2.10.3,0,0
589,### Device(s) and version(s) of Android being used,1,1
590,"Samsung Galaxy S7 Edge, Android 8.0; Huawei Mate 20 lite, Android 8.1; Samsung Galaxy A7 (2018), Android 9",1,1
591,"Also emulators of Pixel 2 devices using Android 8, 9 and Q (9+)",1,0
592,<!-- DO NOT DELETE,0,1
593,validate_template=true,0,0
594,template_path=.github/ISSUE_TEMPLATE/bug.md,0,1
595,-->,0,0
596,**Affects:** 5.1.9.RELEASE,1,1
597,The entry set returned from the result of calling `HttpHeaders.readOnlyHttpHeaders(HttpHeaders)` does not maintain the original headers' ordering. This is a regression from 5.1.0 that I think was introduced in 5.1.1 in https://github.com/spring-projects/spring-framework/commit/ce7278aaf4f20348862267c2081c20dc5bd77128. I believe the set is unordered due to the use of `Collectors.toSet()` which creats an unordered `Set`:,1,1
598,https://github.com/spring-projects/spring-framework/blob/1ea6ce72bb3b1139abc370f6dc32c51fc27ae90b/spring-web/src/main/java/org/springframework/http/ReadOnlyHttpHeaders.java#L146,0,0
599,Which make it very hard to debug issue with sandboxing on OS X.,1,1
600,Affects all versions of 2.x & 3.x,1,1
601,An example not working configuration is here:,1,1
602,```,0,0
603,<network>,0,0
604,<join>,0,0
605,"       <tcp-ip enabled=""""true"""">",0,0
606,<hostname>host-test</hostname>,0,0
607,<hostname>host-test2</hostname>,0,0
608,</tcp-ip>,0,0
609,</join>,0,0
610,"     <interfaces enabled=""""true”> ",0,0
611,<interface>127.0.0.*</interface>,0,0
612,<interface>10.0.2.*</interface>,0,0
613,<interface>10.10.1.*</interface>,0,0
614,<interface>10.0.1.*</interface>,0,0
615,</interfaces>,0,0
616,</network>,0,0
617,```,0,0
618,environment:,1,1
619,demo site version 3.1.2-GA,1,1
620,jboss 7.1.1,1,0
621,tomcat 6,1,0
622,postgresql 9,1,0
623,"generated demo site work perfect on tomcat, the same war files deployed on jboss does not work:",1,1
624,"site war show blank page, nothing in the log",1,1
625,admin war throw exception,1,0
626,Caused by: java.lang.NullPointerException,0,0
627,at org.broadleafcommerce.openadmin.server.service.persistence.PersistenceManagerFactory.getPersistenceManager(PersistenceManagerFactory.java:51) [broadleaf-open-admin-platform-3.1.2-GA.jar:],0,0
628,the reason: spring application context was not set,1,1
629,3.1.1-GA work well on jboss 7.1.1,1,1
630,"When creating a new workspace, a growl type message is shown in the ui saying 'Workspace undefined successfully created'.  I assume this should say 'Workspace -name- successfully created'.",1,1
631,``` diff,0,0
632,--- plugin.bat.orig     2011-06-06 21:57:50 +0100,0,0
633,+++ plugin.bat  2011-06-06 21:57:27 +0100,0,0
634,"@@ -8,7 +8,7 @@",0,0
635," for %%I in (""""%SCRIPT_DIR%.."""") do set ES_HOME=%%~dpfI",0,1
636,"-set ES_CLASSPATH=$CLASSPATH;""""%ES_HOME%/lib/*""""",0,0
637,+set ES_CLASSPATH=%CLASSPATH%;%ES_HOME%/lib/*,0,0
638," set ES_PARAMS=-Delasticsearch -Des.path.home=""""%ES_HOME%""""",0,0
639," """"%JAVA_HOME%\bin\java"""" %JAVA_OPTS% %ES_JAVA_OPTS% %ES_PARAMS% -cp """"%ES_CLASSPATH%"""" """"org.elasticsearch.plugins.PluginManager"""" %*",0,0
640,```,0,0
641,"As discussed [here](https://discuss.graphhopper.com/t/calculating-time-should-not-require-to-read-speed-from-edge-in-wrong-direction/509/9), there are cases that result in an Exception using the CurvatureWeighting.",1,1
642,"Interesting is that in these cases the speed for that edge is 0, but we never set an edge to speed 0 using the getSpeed() method in the CarEncoder.",1,1
643,The weighting returns 0. And we get the following Exception:,1,1
644,```,0,0
645,"java.lang.IllegalStateException: Calculating time should not require to read speed from edge in wrong direction. Reverse:false, fwd:false, bwd:true",0,1
646,at com.graphhopper.routing.Path.calcMillis(Path.java:266),0,0
647,at com.graphhopper.routing.Path.processEdge(Path.java:238),0,0
648,at com.graphhopper.routing.PathBidirRef.extract(PathBidirRef.java:95),0,0
649,at com.graphhopper.routing.DijkstraBidirectionRef.extractPath(DijkstraBidirectionRef.java:132),0,0
650,at com.graphhopper.routing.AbstractBidirAlgo.calcPath(AbstractBidirAlgo.java:64),0,0
651,at com.graphhopper.routing.AbstractRoutingAlgorithm.calcPaths(AbstractRoutingAlgorithm.java:121),0,0
652,at com.graphhopper.GraphHopper.calcPaths(GraphHopper.java:1327),0,0
653,```,0,0
654,"To reproduce this Exception, load the current germany.osm.pbf. And visit this URL: http://localhost:8989/?point=48.873748%2C8.412781&point=49.099864%2C7.993197&locale=de-DE&vehicle=motorcycle&weighting=curvature&elevation=false&layer=Omniscale",1,1
655,"A small update within the method `CalendarText.isRTL(Locale)` is needed for language codes """"sd"""" and """"ug"""". This is in agreement with an analysis of actual CLDR data.",1,1
656,### Expected behavior,1,1
657,Success,1,0
658,### Actual behavior,1,1
659,```,0,0
660,Caused by: java.lang.NullPointerException,0,0
661,	at reactor.core.publisher.Hooks.onEachOperator(Hooks.java:100),0,0
662,	at reactor.core.publisher.Hooks.onEachOperator(Hooks.java:69),0,0
663,	at reactor.core.publisher.Hooks.<clinit>(Hooks.java:476),0,0
664,```,0,0
665,### Steps to reproduce,1,1
666,"1. `Mono.just(""""hello"""").subscribe()`",1,1
667,2. settings `-Dreactor.trace.operatorStacktrace=true`,1,1
668,3. Running programs,1,1
669,### Reactor Core version,1,1
670,`reactor-core:3.1.2.RELEASE`,0,0
671,### JVM version (e.g. `java -version`),1,1
672,`jdk1.8.0_121`,0,0
673,### OS version (e.g. `uname -a`),1,1
674,`Windows`,1,0
675,Initialization of variable order problems,1,1
676,[Hooks.java#L471](https://github.com/reactor/reactor-core/blob/master/reactor-core/src/main/java/reactor/core/publisher/Hooks.java#L471),0,0
677,[Hooks.java#L516](https://github.com/reactor/reactor-core/blob/master/reactor-core/src/main/java/reactor/core/publisher/Hooks.java#L516),0,0
678,"Initialization `globalTrace`  `log` The instance has not been created yet, cause `NullPointerException`",1,1
679,It is very simply to reproduce the issue:,1,1
680,1. ```,1,0
681,"     Download 1.7.8, 2.0.6 community edition from: http://orientdb.com/download/",1,1
682,```,0,0
683,2. ```,1,0
684,Run console: ../orientdb-community-1.7.8/bin/console.bat,1,1
685,```,0,0
686,create database plocal:C:/OrientDB/orientdb-community-1.7.8/databases/test01 admin admin;,1,0
687,create database plocal:C:/OrientDB/orientdb-community-1.7.8/databases/test02 admin admin;,1,0
688,1. ```,1,0
689,Run  ../orientdb-community-1.7.8/bin/dserver.bat notice server start with no exception. Stop it.,1,1
690,```,0,0
691,2. ```,1,0
692,Copy directory: orientdb-community-1.7.8/databases into: ../orientdb-community-2.0.6/databases,1,0
693,```,0,0
694,3. ```,1,0
695,Run  ../orientdb-community-2.0.6/bin/dserver.bat notice exception:,1,0
696,```,1,0
697,2015-04-10 14:29:10:306 INFO  [node1428684304423] adding node 'node1428684304423' in partition: db=t,0,0
698,est02 [*] [OHazelcastDistributedDatabase],0,0
699,2015-04-10 14:29:10:308 WARNING Error deserializing record YXV0b0RlcGxveTp0cnVlLGhvdEFsaWdubWVudDpmY,0,0
700,WxzZSxyZWFkUXVvcnVtOjEsd3JpdGVRdW9ydW06MixmYWlsdXJlQXZhaWxhYmxlTm9kZXNMZXNzUXVvcnVtOmZhbHNlLHJlYWRZb,0,1
701,3VyV3JpdGVzOnRydWUsY2x1c3RlcnM6KGludGVybmFsOigpLGluZGV4OigpLCo6KHNlcnZlcnM6WyI8TkVXX05PREU+Iiwibm9kZ,0,1
702,TE0Mjg2OTM2OTEzMzYiXSkpLHZlcnNpb246MA== send this data for debugging [ORecordSerializerBinary][10.12,0,1
703,5.3.47]:2434 [orientdb] [3.3] hz._hzInstance_1_orientdb.event-2 caught an exception while processing,0,0
704,task:com.hazelcast.spi.impl.EventServiceImpl$LocalEventDispatcher@e968b45,0,0
705,java.lang.ArrayIndexOutOfBoundsException: 97,0,0
706,at com.orientechnologies.orient.core.serialization.serializer.record.binary.ORecordSerialize,0,1
707,rBinary.fromStream(ORecordSerializerBinary.java:72),0,0
708,at com.orientechnologies.orient.core.record.impl.ODocument.deserializeFields(ODocument.java:,0,1
709,1755),0,0
710,at com.orientechnologies.orient.core.record.impl.ODocument.checkForFields(ODocument.java:218,0,0
711,7),0,0
712,at com.orientechnologies.orient.core.record.impl.ODocument.rawField(ODocument.java:834),0,0
713,at com.orientechnologies.orient.core.record.impl.ODocument.field(ODocument.java:854),0,0
714,at com.orientechnologies.orient.server.distributed.ODistributedAbstractPlugin.updateCachedDa,0,1
715,tabaseConfiguration(ODistributedAbstractPlugin.java:220),0,0
716,at com.orientechnologies.orient.server.hazelcast.OHazelcastPlugin.updateCachedDatabaseConfig,0,1
717,uration(OHazelcastPlugin.java:780),0,0
718,at com.orientechnologies.orient.server.hazelcast.OHazelcastPlugin.checkDatabaseEvent(OHazelc,0,1
719,astPlugin.java:1070),0,0
720,at com.orientechnologies.orient.server.hazelcast.OHazelcastPlugin.entryAdded(OHazelcastPlugi,0,1
721,n.java:607),0,0
722,at com.hazelcast.map.MapEventPublishingService.dispatch0(MapEventPublishingService.java:85),0,0
723,at com.hazelcast.map.MapEventPublishingService.dispatchEntryEventData(MapEventPublishingServ,0,1
724,ice.java:64),0,0
725,at com.hazelcast.map.MapEventPublishingService.dispatchEvent(MapEventPublishingService.java:,0,1
726,39),0,0
727,at com.hazelcast.map.MapEventPublishingService.dispatchEvent(MapEventPublishingService.java:,0,1
728,17),0,0
729,at com.hazelcast.map.MapService.dispatchEvent(MapService.java:76),0,0
730,at com.hazelcast.map.MapService.dispatchEvent(MapService.java:51),0,0
731,at com.hazelcast.spi.impl.EventServiceImpl$LocalEventDispatcher.run(EventServiceImpl.java:65,0,0
732,8),0,0
733,at com.hazelcast.util.executor.StripedExecutor$Worker.process(StripedExecutor.java:189),0,0
734,at com.hazelcast.util.executor.StripedExecutor$Worker.run(StripedExecutor.java:173),0,0
735,2015-04-10 14:29:10:320 WARNING [node1428684304423] updated distributed configuration for database:,0,0
736,test02:,0,1
737,"Thanks,",1,1
738,Vasil,1,0
739,Hi there!,1,1
740,I spotted something that might be wrong with the OSX `.gitgnore` template.,1,1
741,Here is the generated file I've got:,1,1
742,```,0,0
743,# Created by .ignore support plugin (hsz.mobi),0,0
744,### OSX template,0,1
745,.DS_Store,0,0
746,.AppleDouble,0,0
747,.LSOverride,0,0
748,# Icon must end with two \r,0,1
749,Icon,0,0
750,# Thumbnails,0,0
751,._*,0,0
752,# Files that might appear in the root of a volume,0,1
753,.DocumentRevisions-V100,0,0
754,.fseventsd,0,0
755,.Spotlight-V100,0,0
756,.TemporaryItems,0,0
757,.Trashes,0,0
758,.VolumeIcon.icns,0,0
759,# Directories potentially created on remote AFP share,0,1
760,.AppleDB,0,0
761,.AppleDesktop,0,0
762,Network Trash Folder,0,0
763,Temporary Items,0,0
764,.apdisk,0,0
765,```,0,0
766,The error lies here:,1,1
767,```,0,0
768,# Icon must end with two \r,0,1
769,Icon,0,0
770,```,0,0
771,"Actually, it seems that there're 2 `\0` characters instead of 2 `\r`, which might break things [as I ran into some issues with git-related tools](http://forums.gitup.co/t/unhandled-character-in-gitignore/278).",1,1
772,I'm not sure it was expected so I'm reporting as it looks like an issue.,1,1
773,"For comparison, here is the diff with the http://www.gitignore.io version (which is on the left):",1,1
774,![capture d ecran 2015-07-30 a 09 05 02](https://cloud.githubusercontent.com/assets/1094774/8977538/54e0039c-369a-11e5-8ffc-0402ba7544c8.png),0,0
775,Thanks a lot for your useful plugin by the way :+1:,1,1
776,from pull #3918 discussion.,1,1
777,Looks like we have the same problem for ```DEFAULT_TOKEN```. I think that it should be fixed in separate issue.,1,0
778,````,0,0
779,$ cat TestClass.java,0,0
780,public class TestClass {,0,0
781,void method(int a) {,0,0
782,switch (a) {},0,0
783,switch (a) {default: },0,0
784,switch (a) {default: {}} // violation is expected,0,0
785,switch (a) {,0,0
786,default:,0,1
787,},0,0
788,switch (a) {,0,0
789,default: // violation is expected,0,0
790,{},0,0
791,},0,0
792,switch (a) {,0,0
793,default: // violation is expected,0,0
794,{,0,0
795,},0,0
796,},0,0
797,},0,0
798,},0,0
799,$ cat TestConfig.xml,0,0
800,"<?xml version=""""1.0""""?>",0,0
801,<!DOCTYPE module PUBLIC,0,0
802,"          """"-//Puppy Crawl//DTD Check Configuration 1.3//EN""""",0,0
803,"          """"http://www.puppycrawl.com/dtds/configuration_1_3.dtd"""">",0,0
804,"<module name=""""Checker"""">",0,0
805,"    <property name=""""charset"""" value=""""UTF-8""""/>",0,0
806,"<module name=""""TreeWalker"""">",0,0
807,"        <module name=""""EmptyBlock"""">",0,0
808,"            <property name=""""tokens"""" value=""""LITERAL_DEFAULT""""/>",0,0
809,</module>,0,0
810,</module>,0,0
811,</module>,0,0
812,$ java -jar checkstyle-7.6-all.jar -c TestConfig.xml TestClass.java,0,0
813,Starting audit...,0,1
814,Audit done.,0,1
815,````,0,0
816,"Hi Team,",1,1
817," When pre roll ad is playing and app goes in background and comes back in foreground, app crashes. Here is the stack trace.",1,1
818,`FATAL EXCEPTION: main Process:,0,1
819,PID: 22373 java.lang.NullPointerException: Attempt to invoke interface method 'void com.google.ads.interactivemedia.v3.api.AdsManager.resume()' on a null object reference at com.google.android.exoplayer2.ext.ima.ImaAdsLoader.attachPlayer(ImaAdsLoader.java:396) at com.google.android.exoplayer2.source.ads.AdsMediaSource$2.run(AdsMediaSource.java:219) at android.os.Handler.handleCallback(Handler.java:789) at android.os.Handler.dispatchMessage(Handler.java:98) at android.os.Looper.loop(Looper.java:164) at android.app.ActivityThread.main(ActivityThread.java:6809) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)`,0,0
820,Here are my onresume and onpause methods of fragment:,1,1
821,` @Override,0,0
822,public void onResume() {,0,0
823,super.onResume();,0,0
824,"        player.init(getActivity(), playerView);",0,0
825,}`,0,0
826,` @Override,0,0
827,public void onPause() {,0,0
828,super.onPause();,0,0
829,player.reset();,0,0
830,player.release();,0,0
831,playerView.getPlayer().release();,0,0
832,}`,0,0
833,Please help me with the same.,1,1
834,"In PoolingHttpDestination:process(final C connection, boolean dispatch) a check is performed to ensure the request was not aborted before being associated with a connection and if it was then the connection is neither released or closed. Might be useful to move the connection release code below in a separate method and use it for both cases - i.e. when there's no exchange or the request was aborted prior to creation of the exchange.",1,1
835,```,0,0
836,"public void process(final C connection, boolean dispatch)",0,0
837,{,0,0
838,HttpClient client = getHttpClient();,0,0
839,final HttpExchange exchange = getHttpExchanges().poll();,0,0
840,if (LOG.isDebugEnabled()),0,0
841,"            LOG.debug(""""Processing exchange {} on {} of {}"""", exchange, connection, this);",0,0
842,if (exchange == null),0,0
843,{,0,0
844,if (!connectionPool.release(connection)),0,0
845,connection.close();,0,0
846,if (!client.isRunning()),0,0
847,{,0,0
848,if (LOG.isDebugEnabled()),0,0
849,"                    LOG.debug(""""{} is stopping"""", client);",0,0
850,connection.close();,0,0
851,},0,0
852,},0,0
853,else,0,1
854,{,0,0
855,final Request request = exchange.getRequest();,0,0
856,Throwable cause = request.getAbortCause();,0,0
857,if (cause != null),0,0
858,{,0,0
859,if (LOG.isDebugEnabled()),0,0
860,"                    LOG.debug(""""Aborted before processing {}: {}"""", exchange, cause);",0,0
861,// It may happen that the request is aborted before the exchange,0,0
862,// is created. Aborting the exchange a second time will result in,0,0
863,"                // a no-operation, so we just abort here to cover that edge case.",0,0
864,exchange.abort(cause);,0,0
865,},0,0
866,else,0,1
867,{,0,0
868,if (dispatch),0,0
869,{,0,0
870,client.getExecutor().execute(new Runnable(),0,0
871,{,0,0
872,@Override,0,0
873,public void run(),0,0
874,{,0,0
875,"                            send(connection, exchange);",0,0
876,},0,0
877,});,0,0
878,},0,0
879,else,0,1
880,{,0,0
881,"                    send(connection, exchange);",0,0
882,},0,0
883,},0,0
884,},0,0
885,},0,0
886,```,0,0
887,The same column of type INTEGER in raw query can be mapped to Long or to Integer.,1,1
888,"The problem occurs because type mapping is stored in `Map` class, and the type mapping method:",1,1
889,https://github.com/requery/requery/blob/14a8ac29a4a97872878ae773fc8c96d3e7c10dbb/requery/src/main/java/io/requery/sql/GenericMapping.java#L249,0,0
890,Just iterates through that map to get mapped type.,1,1
891,Types map looks like this:,1,1
892,```,0,0
893,"0 = {AbstractMap$SimpleEntry@8270} """"class java.sql.Timestamp"""" -> """"TIMESTAMP""""",0,0
894,"1 = {AbstractMap$SimpleEntry@8271} """"class java.lang.Boolean"""" -> """"BOOLEAN""""",0,0
895,"2 = {AbstractMap$SimpleEntry@8272} """"class java.lang.String"""" -> """"VARCHAR(255)""""",0,0
896,"3 = {AbstractMap$SimpleEntry@8273} """"class java.math.BigDecimal"""" -> """"DECIMAL""""",0,0
897,"4 = {AbstractMap$SimpleEntry@8274} """"float"""" -> """"FLOAT""""",0,0
898,"5 = {AbstractMap$SimpleEntry@8275} """"class java.lang.Double"""" -> """"REAL""""",0,0
899,"6 = {AbstractMap$SimpleEntry@8276} """"interface java.sql.Blob"""" -> """"BLOB""""",0,0
900,"7 = {AbstractMap$SimpleEntry@8277} """"interface java.sql.Clob"""" -> """"CLOB""""",0,0
901,"8 = {AbstractMap$SimpleEntry@8278} """"class java.lang.Byte"""" -> """"TINYINT""""",0,0
902,"9 = {AbstractMap$SimpleEntry@8279} """"short"""" -> """"SMALLINT""""",0,0
903,"10 = {AbstractMap$SimpleEntry@8280} """"class java.lang.Short"""" -> """"SMALLINT""""",0,0
904,"11 = {AbstractMap$SimpleEntry@8281} """"class [B"""" -> """"VARBINARY(null)""""",0,0
905,"12 = {AbstractMap$SimpleEntry@8282} """"class java.sql.Date"""" -> """"DATE""""",0,0
906,"13 = {AbstractMap$SimpleEntry@8283} """"int"""" -> """"INTEGER""""",0,0
907,"14 = {AbstractMap$SimpleEntry@8284} """"class java.lang.Integer"""" -> """"INTEGER""""",0,0
908,"15 = {AbstractMap$SimpleEntry@8285} """"class java.lang.Long"""" -> """"INTEGER""""",0,0
909,"16 = {AbstractMap$SimpleEntry@8286} """"boolean"""" -> """"BOOLEAN""""",0,0
910,"17 = {AbstractMap$SimpleEntry@8287} """"class java.lang.Float"""" -> """"FLOAT""""",0,0
911,"18 = {AbstractMap$SimpleEntry@8288} """"long"""" -> """"INTEGER""""",0,0
912,"19 = {AbstractMap$SimpleEntry@8289} """"byte"""" -> """"TINYINT""""",0,0
913,"20 = {AbstractMap$SimpleEntry@8290} """"class java.sql.Time"""" -> """"TIME""""",0,0
914,"21 = {AbstractMap$SimpleEntry@8291} """"double"""" -> """"REAL""""",0,0
915,"22 = {AbstractMap$SimpleEntry@8292} """"class java.util.Date"""" -> """"DATE""""",0,0
916,```,0,0
917,"So, you see - SQL INTEGER type corresponds to Long and to Integer java types.",1,1
918,"As `Map` does not guarantee consistent iteration order, we get different results in different situations - at least, the same code on API-22 returns Integer, while on API-19 - Long. Maybe there are other factors.",1,1
919,So it's impossible to use raw queries with `Long` or `Integer` fields - app just crashes because of incompatible types.,1,1
920,P.S. for now my work-around was to use custom Mapping class.,1,1
921,I have a Boot application that has a servlet filter to apply CORS headers to responses in certain scenarios.,1,1
922,"In 1.1.4, when I make an OPTIONS call to my application, I get the response I'm expecting.",1,1
923,"In 1.1.5, the CORS headers I'm expecting are missing, and no exception is generated in the logs. However, if I look at the `/manage/trace` endpoint, I see two things: 1) the OPTIONS request for some reason is returning an HTTP status of """"0""""; 2) the server is sending an error and the trace has a stack in it.",1,1
924,Can someone help me understand why an HTTP status code of 0 is being returned?,1,1
925,"Also, the code in 1.1.5 for `MetricFilterAutoConfiguration` has a change that does not gracefully handle the 0 status, while the code in 1.1.4 does handle it.",1,1
926,Here is the stack that I found in the trace endpoint:,1,1
927,```,0,0
928,java.lang.IllegalArgumentException: No matching constant for [0],0,0
929,at org.springframework.http.HttpStatus.valueOf(HttpStatus.java:467),0,0
930,at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:99),0,0
931,at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107),0,0
932,at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1480),0,0
933,at org.springframework.boot.context.web.ErrorPageFilter.doFilter(ErrorPageFilter.java:108)\n\tat,0,0
934,```,0,0
935,A corrupt ICC header may cause java.awt.color.ICC_Profile to allocate a huge read buffer resulting in an OutOfMemory exception. You may want to catch this in the TIFFImageReader.getICCProfile() like this:,1,1
936,catch (CMMException | IllegalArgumentException | **OutOfMemoryError** ignore) {,0,0
937,"        processWarningOccurred(""""Ignoring broken/incompatible ICC profile: """" + ignore.getMessage());",0,0
938,},0,0
939,"The `query_string` query has `<` and `>` operators that make it easy to build range queries. For instance, `age:>18` is equivalent to `age:{18 TO *]`. The issue however is that given that it is implemented on top of the base Lucene query parser (`<` and `>` are handled in `MapperQueryParser#getFieldQuerySingle`), they cannot be escaped like other query operators. So if you want to search for a term that starts with `<` or `>` in a `keyword` field, the only way to do so is to quote the searched term, eg. `my_field:"""">value""""`.",1,1
940,I use Elasticsearch with Logstash and dynamic mapping.,1,1
941,"I my logs, I have geopoints with the array syntax.",1,1
942,"It was OK with ES 1.0.X, but it's broken with ES 1.2.2.",1,1
943,Template:,1,1
944,```,0,0
945,curl -XPUT localhost:9200/_template/logstash -d '{,0,0
946,"    """"template"""": """"logstash_*"""",",0,0
947,"    """"settings"""" : {",0,0
948,"        """"refresh_interval"""": """"30s""""",0,0
949,"    },",0,0
950,"    """"mappings"""": {",0,0
951,"        """"logs"""": {",0,0
952,"            """"_all"""" : {",0,0
953,"                """"enabled"""": false",0,0
954,"            },",0,0
955,"            """"dynamic_templates"""": [",0,0
956,{,0,0
957,"                    """"location"""": {",0,0
958,"                        """"match"""": """"location*"""",",0,0
959,"                        """"mapping"""": {",0,0
960,"                            """"type"""": """"geo_point""""",0,0
961,},0,0
962,},0,0
963,"                },",0,0
964,{,0,0
965,"                    """"generic"""": {",0,0
966,"                        """"match"""": """"*"""",",0,0
967,"                        """"match_mapping_type"""": """"string"""",",0,0
968,"                        """"mapping"""": {",0,0
969,"                            """"type"""": """"string"""",",0,0
970,"                            """"index"""": """"not_analyzed""""",0,0
971,},0,0
972,},0,0
973,},0,0
974,"            ],",0,0
975,"            """"dynamic_date_formats"""": [",0,0
976,"                """"dateOptionalTime"""",",0,0
977,"                """"yyyy-MM-dd"""",",0,0
978,"                """"yyyy-MM-dd HH:mm:ss""""",0,0
979,],0,0
980,},0,0
981,},0,0
982,}',0,0
983,```,0,0
984,Delete index:,1,1
985,```,0,0
986,curl -XDELETE localhost:9200/logstash_test,0,0
987,```,0,0
988,Try to add a doc/log:,1,1
989,```,0,0
990,curl -XPOST localhost:9200/logstash_test/logs -d '{,0,0
991,"  """"location_array"""": [",0,0
992,"    2.3069244,",0,0
993,48.8881598,0,0
994,],0,0
995,}',0,0
996,```,0,0
997,It fails with this message:,1,1
998,```,0,0
999,"[2014-07-21 11:31:49,168][INFO ][cluster.metadata         ] [fr-dev-01] [logstash_test] creating index, cause [auto(index api)], shards [5]/[1], mappings [logs]",0,0
1000,"[2014-07-21 11:31:49,465][DEBUG][action.index             ] [fr-dev-01] [logstash_test][1], node[zzMEQe9JSS6qEgw0oRgdVA], [P], s[STARTED]: Failed to execute [index {[logstash_test][logs][PhqP9fpgQkS4tHfOs105GQ], source[{""""location_array"""":[2.3069244,48.8881598]}]}]",0,0
1001,org.elasticsearch.index.mapper.MapperParsingException: failed to parse,0,0
1002,at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:536),0,0
1003,at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:462),0,0
1004,at org.elasticsearch.index.shard.service.InternalIndexShard.prepareCreate(InternalIndexShard.java:373),0,0
1005,at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:203),0,0
1006,at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$AsyncShardOperationAction.performOnPrimary(TransportShardReplicationOperationAction.java:534),0,0
1007,at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$AsyncShardOperationAction$1.run(TransportShardReplicationOperationAction.java:433),0,0
1008,at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145),0,0
1009,at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615),0,0
1010,at java.lang.Thread.run(Thread.java:724),0,0
1011,Caused by: org.elasticsearch.ElasticsearchParseException: geo_point expected,0,0
1012,at org.elasticsearch.common.geo.GeoUtils.parseGeoPoint(GeoUtils.java:421),0,0
1013,at org.elasticsearch.index.mapper.geo.GeoPointFieldMapper.parse(GeoPointFieldMapper.java:530),0,0
1014,at org.elasticsearch.index.mapper.object.ObjectMapper.parseDynamicValue(ObjectMapper.java:819),0,0
1015,at org.elasticsearch.index.mapper.object.ObjectMapper.serializeValue(ObjectMapper.java:639),0,0
1016,at org.elasticsearch.index.mapper.object.ObjectMapper.serializeArray(ObjectMapper.java:625),0,0
1017,at org.elasticsearch.index.mapper.object.ObjectMapper.parse(ObjectMapper.java:482),0,0
1018,at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:515),0,0
1019,... 8 more,0,0
1020,```,0,0
1021,"If I insert a doc with a geopoint as an object, it works, and the mapping is created dynamically.",1,1
1022,"After that, I can insert a doc with a geopoint as an array without error.",1,1
1023,'/var/tmp $ javac Test.java':,0,0
1024,`/var/tmp $ cat Test.java`:,0,0
1025,```,0,0
1026,/*,0,0
1027,-----------------------------------------------------------------------------------,0,0
1028,example,0,1
1029,Copyright (c) 2001-2018 XXX,0,1
1030,-----------------------------------------------------------------------------------,0,0
1031,*/,0,0
1032,public class Test {,0,0
1033,public Test() {,0,0
1034,},0,0
1035,},0,0
1036,```,0,0
1037,`/var/tmp $ cat checkstyle.header`:,0,0
1038,```,0,0
1039,/*,0,0
1040,-----------------------------------------------------------------------------------,0,0
1041,example,0,1
1042,Copyright (c) 2001-2018 XXX,0,1
1043,-----------------------------------------------------------------------------------,0,0
1044,*/,0,0
1045,```,0,0
1046,`/var/tmp $ cat config.xml`:,0,0
1047,```,0,0
1048,"<?xml version=""""1.0"""" encoding=""""ISO-8859-1""""?>",0,0
1049,<!DOCTYPE module PUBLIC,0,0
1050,"    """"-//Puppy Crawl//DTD Check Configuration 1.3//EN""""",0,0
1051,"    """"http://www.puppycrawl.com/dtds/configuration_1_3.dtd"""">",0,0
1052,"<module name=""""Checker"""">",0,0
1053,"  <module name=""""Header"""">",0,0
1054,"    <property name=""""headerFile"""" value=""""checkstyle.header""""/>",0,0
1055,"    <property name=""""fileExtensions"""" value=""""java""""/>",0,0
1056,</module>,0,0
1057,</module>,0,0
1058,```,0,0
1059,`/var/tmp $ java -Duser.language=en -Duser.country=US -jar checkstyle-8.8-all.jar -c config.xml Test.java`:,0,0
1060,```,0,0
1061,"Feb 05, 2018 8:00:11 PM com.puppycrawl.tools.checkstyle.Main runCli",0,0
1062,FINE: Checkstyle debug logging enabled,0,0
1063,"Feb 05, 2018 8:00:11 PM com.puppycrawl.tools.checkstyle.Main runCli",0,0
1064,FINE: Running Checkstyle with version: 8.8,0,1
1065,Starting audit...,0,1
1066,[ERROR] /data1/home/martin/x_checkstyle/Test.java:3: Line does not match expected header line of '^$'. [Header],0,0
1067,Audit done.,0,1
1068,Checkstyle ends with 1 errors.,0,1
1069,```,0,0
1070,---------------,0,0
1071,I found this issue upgrading from version 6.7 to 8.8.,1,1
1072,The Header check does not match the empty lines like expected.,1,1
1073,"Looking through the CheckStyle source I would guess that the AbstractHeaderCheck method loadHeader is converting empty lines to """"^$"""" what cannot work with the equals in the HeaderCheck isMatch method.",1,1
1074,"A few days ago I noticed that my websocket clients are being disconnected in weird way. I found that, when upgrade is complete, exception below is being thrown from HttpResponseDecoder and WebSocketClientProtocolHandler just closes connection on exception. And this happens only if i use pooled allocator for channels.",1,1
1075,```,0,0
1076,io.netty.handler.codec.DecoderException: io.netty.util.IllegalReferenceCountException: refCnt: 0,0,0
1077,at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:391),0,0
1078,at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244),0,0
1079,at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:318),0,0
1080,at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:304),0,0
1081,at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846),0,0
1082,at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131),0,0
1083,at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511),0,0
1084,at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468),0,0
1085,at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382),0,0
1086,at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354),0,0
1087,at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:112),0,0
1088,at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137),0,0
1089,at java.lang.Thread.run(Thread.java:745),0,0
1090,Caused by: io.netty.util.IllegalReferenceCountException: refCnt: 0,0,0
1091,at io.netty.buffer.AbstractByteBuf.ensureAccessible(AbstractByteBuf.java:1190),0,0
1092,at io.netty.buffer.AbstractByteBuf.checkReadableBytes0(AbstractByteBuf.java:1176),0,0
1093,at io.netty.buffer.AbstractByteBuf.checkReadableBytes(AbstractByteBuf.java:1172),0,0
1094,at io.netty.buffer.AbstractByteBuf.readBytes(AbstractByteBuf.java:672),0,0
1095,at io.netty.handler.codec.http.HttpObjectDecoder.decode(HttpObjectDecoder.java:390),0,0
1096,at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:360),0,0
1097,... 12 more,0,0
1098,```,0,0
1099,System info,1,0
1100,```,0,0
1101,Linux Atplaychannel 3.5.0-17-generic #28-Ubuntu SMP Tue Oct 9 19:31:23 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux,0,1
1102,```,0,0
1103,Java version,1,1
1104,```,0,0
1105,"java version """"1.8.0_66""""",0,1
1106,Java(TM) SE Runtime Environment (build 1.8.0_66-b17),0,1
1107,"Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode)",0,0
1108,```,0,0
1109,This happens only when first websocket frame is being received in same packet as upgrade response.,1,1
1110,Netty version is 4.0.33.Final and it looks like that previous versions don't have this issue.,1,1
1111,Code that reproduces the issue https://gist.github.com/lexek/b61d0980f029f47b353b,1,1
1112,The plugin script now will automatically download plugins from `download.elasticsearch.org` instead of github. It will also try maven (both central and sonatype) if it fails.,1,1
1113,"Effectively, this change removes the ability to install plugins from the downloads section in github, since its no longer supported by github. Site plugins can still be installed by downloading the """"repo"""".",1,1
1114,"Direct installation is still supported, using the `bin/plugin -url file://path/to/plugin -name plugin-name`.",1,1
1115,### Expected behavior,1,1
1116,No null pointer exceptions,1,1
1117,### Actual behavior,1,1
1118,"When an HTTP/1.1 upgrade request comes in, we call `onHttpServerUpgrade` in Http2ConnectionHandler.  This makes us create a stream, which eventually calls `new DefaultHttp2StreamChannel`, which is fine, except that it assumes that handlerAdded has already been called on Http2MultiplexCodec . . . which is always true except when we're doing a cleartext upgrade.",1,1
1119,### Steps to reproduce,1,1
1120,"Make an HttpServerUpgradeHandler, with an Http2MultiplexCodec.  Send an h2c upgrade request.",1,1
1121,### Minimal yet complete reproducer code (or URL to code),1,1
1122,Try to upgrade this to netty 4.1.15.,1,1
1123,https://github.com/twitter/finagle/blob/develop/finagle-http2/src/main/scala/com/twitter/finagle/http2/Http2CleartextServerInitializer.scala#L74,0,1
1124,### Netty version,1,1
1125,4.1.15.Final,0,0
1126,Following on from issue #8314 if I attempt to set management.security.roles to an array using the config below I get an `UnsupportedOperationException` thrown from `java.util.AbstractList#add` for the second element,1,1
1127,```,0,0
1128,management:,0,1
1129,context-path: /management,0,0
1130,security:,0,1
1131,enabled: true,0,0
1132,roles:,0,1
1133,"    - CN=some-group,OU=somewhere,OU=in,OU=ldap,DC=example,DC=com",0,1
1134,"    - CN=some-other-group,OU=somewhere,OU=in,OU=ldap,DC=example,DC=com",0,1
1135,```,0,0
1136,I have updated https://github.com/jonfreedman/spring-boot-management-demo to illustrate,1,1
1137,"Just as an information, when I start the app with the most current version of Realm I get the following log messages:",1,1
1138,```,0,0
1139,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$4>,0,0
1140,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$4>,0,0
1141,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$3>,0,0
1142,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$3>,0,0
1143,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$2>,0,0
1144,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$2>,0,0
1145,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$1>,0,0
1146,I/art: Rejecting re-init on previously-failed class java.lang.Class<io.realm.rx.RealmObservableFactory$1>,0,0
1147,```,0,0
1148,"We are currently not using the new `rx`feature, but just wanted to see if this is something to be concerned about.",1,1
1149,The device was a Nexus 5 running Android 6.,1,1
1150,"In the `org.springframework.boot.autoconfigure.jmx.ParentAwareNamingStrategy.getObjectName(Object, String)` method the contents of the `StringBuilder` builder variable are updated, but never queried.",1,1
1151,"The distributed map seems to loose data, when you try to put an already mapped key into the map after another member has been started. I found this behaviour in the Version 2.0.2 and 2.1 snapshot build. Didn't try any 1.x version. I am using two Win7 64 Bit machines with jdk 1.7u3.",1,1
1152,Steps to reproduce the problem:,1,1
1153,- Start one hazelcast server,1,1
1154,- Fill a map with some simple data:,1,1
1155,``` java,0,0
1156,public static void main(String[] args) {,0,0
1157,int startKey = 0;,0,0
1158,int numberOfKeys = 10;,0,0
1159,Random rand = new Random();,0,0
1160,ClientConfig clientConfig = new ClientConfig();,0,0
1161,"        clientConfig.getGroupConfig().setName(""""dev"""").setPassword(""""dev-pass"""");",0,0
1162,clientConfig.addAddress(Globals.serverNames);,0,0
1163,HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig);,0,0
1164,"        IMap<Long, Long> myMap = client.getMap(""""mydata"""");",0,0
1165,for (int i = startKey; i < (startKey+numberOfKeys); i++) {,0,0
1166,Long key = new Long(i);,0,0
1167,myMap.lock(key);,0,0
1168,"            myMap.put(key, new Long(rand.nextInt()));",0,0
1169,myMap.unlock(key);,0,0
1170,System.out.println(new Long(i).toString());,0,0
1171,},0,0
1172,myMap.flush();,0,0
1173,System.out.println(myMap.size());,0,0
1174,client.getLifecycleService().shutdown();,0,0
1175,},0,0
1176,```,0,0
1177,- List the keys of the map:,1,1
1178,``` java,0,0
1179,public static void main(String[] args) {,0,0
1180,ClientConfig clientConfig = new ClientConfig();,0,0
1181,"        clientConfig.getGroupConfig().setName(""""dev"""").setPassword(""""dev-pass"""");",0,0
1182,clientConfig.addAddress(Globals.serverNames);,0,0
1183,HazelcastInstance client = HazelcastClient.newHazelcastClient(clientConfig);,0,0
1184,PartitionService partitionService = client.getPartitionService();,0,0
1185,"        Map<Long, Long> myMap = client.getMap(""""mydata"""");",0,0
1186,Set keys = myMap.keySet();,0,0
1187,Iterator<Long> iter = keys.iterator();,0,0
1188,int counter = 0;,0,0
1189,while (iter.hasNext()) {,0,0
1190,Long t  = iter.next();,0,0
1191,Partition partition = partitionService.getPartition(t);,0,0
1192,Member ownerMember = partition.getOwner();,0,0
1193,"            System.out.println(t + """";"""" + ownerMember.toString());",0,0
1194,counter++;,0,0
1195,},0,0
1196,"        System.out.println(""""Number of keys: """" + counter);",0,0
1197,client.getLifecycleService().shutdown();,0,0
1198,},0,0
1199,```,0,0
1200,Output:,1,1
1201,```,0,0
1202,0;Member [192.168.0.4]:5701,0,0
1203,1;Member [192.168.0.4]:5701,0,0
1204,2;Member [192.168.0.4]:5701,0,0
1205,3;Member [192.168.0.4]:5701,0,0
1206,4;Member [192.168.0.4]:5701,0,0
1207,5;Member [192.168.0.4]:5701,0,0
1208,6;Member [192.168.0.4]:5701,0,0
1209,7;Member [192.168.0.4]:5701,0,0
1210,8;Member [192.168.0.4]:5701,0,0
1211,9;Member [192.168.0.4]:5701,0,0
1212,Number of keys: 10,0,1
1213,```,0,0
1214,- Start a second hazelcast server,1,1
1215,- List the keys again:,1,1
1216,Output:,1,1
1217,```,0,0
1218,0;Member [192.168.0.4]:5701,0,0
1219,1;Member [192.168.0.4]:5701,0,0
1220,2;Member [192.168.0.5]:5701,0,0
1221,3;Member [192.168.0.4]:5701,0,0
1222,4;Member [192.168.0.4]:5701,0,0
1223,5;Member [192.168.0.5]:5701,0,0
1224,6;Member [192.168.0.4]:5701,0,0
1225,7;Member [192.168.0.4]:5701,0,0
1226,8;Member [192.168.0.5]:5701,0,0
1227,9;Member [192.168.0.5]:5701,0,0
1228,Number of keys: 10,0,1
1229,```,0,0
1230,Some of the keys have changed ownership - just as expected.,1,1
1231,- Now run the code the fill the map again.,1,1
1232,- List the keys again:,1,1
1233,Output:,1,1
1234,```,0,0
1235,0;Member [192.168.0.4]:5701,0,0
1236,1;Member [192.168.0.4]:5701,0,0
1237,3;Member [192.168.0.4]:5701,0,0
1238,4;Member [192.168.0.4]:5701,0,0
1239,6;Member [192.168.0.4]:5701,0,0
1240,7;Member [192.168.0.4]:5701,0,0
1241,Number of keys: 6,0,1
1242,```,0,0
1243,"All the migrated keys are missing. When setting the log level to finest, the second hazelcast server tells me, that it is evicting 4 entries. If you run the code to fill the map again, everything will be fine. I tried it with a lot of different map properties - none seem to solve this problem. Changes to the code (for example setting the ttl with put, setting a lock on the map, using replace instead of put for second mapping) didn't help.",1,1
1244,**Describe the bug**,1,1
1245,"escape/unescape fails with string mode """"javascript""""",1,1
1246,**To Reproduce**,1,1
1247,"Start with the letter """"Ä"""" as cell value",1,1
1248,"escape/unescape works fine using string mode """"html""""",1,1
1249,"Ä > escape(value, """"html"""") > &Auml; > unescape(value, """"html"""") > Ä",0,0
1250,"But it fails when using string mode """"javascript""""",1,1
1251,"Ä > escape(value, """"javascript"""") > \u00C4 > unescape(value, """"javascript"""") > \\\u00C4",0,0
1252,**Current Results**,1,1
1253,unescape does not reverse escape,1,1
1254,**Expected behavior**,1,1
1255,unescape should reverse escape,1,1
1256,**Desktop (please complete the following information):**,1,1
1257,- OS: Windows,1,1
1258,- Browser chrome,1,1
1259,- Version 67.0.3396.99,1,1
1260,**OpenRefine (please complete the following information):**,1,1
1261,- Version OpenRefine 3.0 Beta,1,1
1262,I have observed that if you have multiple scenarios in a feature and you run the scenarios in parallel then you can (quite reliably) get a wrong karate.tagValues in your scenario.,1,1
1263,I have attached a minimal project where this issue can be reproduced: [paralleltags.zip](https://github.com/intuit/karate/files/2782951/paralleltags.zip).,1,1
1264,"If you execute the SequentialRunner then all tests pass as expected, but with the ParallelRunner they don't. Sometimes tests run fine with the ParallelRunner, so I suspect there is a race condition somewhere.",1,1
1265,Please let me know should you need any more information.,1,1
1266,The spring plugin overlaps with the enterprise spring plugin and is not maintained properly. We should remove the OSS Spring plugin and only use the Enterprise Spring plugin.,1,1
1267,"When the config model is loaded from a JSON file, the tree gets updated but the underlying HashMap is not. The result of this is that the JSON file that is created when the project is saved lacks many of the fields. The problem is not apparent since the observable model is correct, it is only the underlying map that is incorrect.",1,1
1268,**Steps to reproduce:**,1,1
1269,1. Create a new project and open UI (works),1,1
1270,2. Connect to database and generate code (works),1,1
1271,3. Close UI and open it again so that the JSON file is loaded (here is where something happens),1,1
1272,4. Generate code again (the generated .json-file is wrong),1,1
1273,"The settings are loaded into the JavaFX-components correctly, but when the map is passed to the generator, it looks like it is an old version of the map.",1,1
1274,This issue only exists in the current `develop` branch.,1,1
1275,### OrientDB Version: v3.0.3,1,1
1276,### Java Version: 8,1,1
1277,### OS: macOS High Sierra,1,1
1278,## Expected behavior,1,1
1279,On issuing update edge command the endpoint should update.  This worked in v2.2.35 but its not working in v3.0.3.,1,1
1280,## Actual behavior,1,1
1281,It's throwing a error saying out is not a vertex and is failing on validateOutInForEdge.,1,1
1282,`com.orientechnologies.orient.core.exception.OCommandExecutionException: Error updating edge: 'out' is not a vertex - [V#9:0{name:a} v1],0,0
1283,"	DB name=""""test""""",0,0
1284,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.validateOutInForEdge(UpdateEdgePointersStep.java:126),0,0
1285,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.handleUpdateEdge(UpdateEdgePointersStep.java:86),0,0
1286,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.access$000(UpdateEdgePointersStep.java:16),0,0
1287,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep$1.next(UpdateEdgePointersStep.java:35),0,0
1288,	at com.orientechnologies.orient.core.sql.executor.SaveElementStep$1.next(SaveElementStep.java:37),0,0
1289,	at com.orientechnologies.orient.core.sql.executor.CountStep.syncPull(CountStep.java:53),0,0
1290,	at com.orientechnologies.orient.core.sql.executor.OSelectExecutionPlan.fetchNext(OSelectExecutionPlan.java:37),0,0
1291,	at com.orientechnologies.orient.core.sql.executor.OUpdateExecutionPlan.executeInternal(OUpdateExecutionPlan.java:46),0,0
1292,	at com.orientechnologies.orient.core.sql.parser.OUpdateStatement.execute(OUpdateStatement.java:144),0,0
1293,	at com.orientechnologies.orient.core.sql.parser.OStatement.execute(OStatement.java:59),0,0
1294,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentEmbedded.command(ODatabaseDocumentEmbedded.java:540),0,0
1295,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommand.executeStatement(OServerCommandPostCommand.java:175),0,0
1296,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommand.execute(OServerCommandPostCommand.java:84),0,0
1297,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommandGraph.execute(OServerCommandPostCommandGraph.java:36),0,0
1298,	at com.orientechnologies.orient.server.network.protocol.http.ONetworkProtocolHttpAbstract.service(ONetworkProtocolHttpAbstract.java:172),0,0
1299,	at com.orientechnologies.orient.server.network.protocol.http.ONetworkProtocolHttpAbstract.execute(ONetworkProtocolHttpAbstract.java:633),0,0
1300,	at com.orientechnologies.common.thread.OSoftThread.run(OSoftThread.java:82),0,0
1301,Internal server error:,0,1
1302,com.orientechnologies.orient.core.exception.OCommandExecutionException: Error updating edge: 'out' is not a vertex - [V#9:0{name:a} v1],0,0
1303,"	DB name=""""test""""",0,0
1304,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.validateOutInForEdge(UpdateEdgePointersStep.java:126),0,0
1305,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.handleUpdateEdge(UpdateEdgePointersStep.java:86),0,0
1306,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep.access$000(UpdateEdgePointersStep.java:16),0,0
1307,	at com.orientechnologies.orient.core.sql.executor.UpdateEdgePointersStep$1.next(UpdateEdgePointersStep.java:35),0,0
1308,	at com.orientechnologies.orient.core.sql.executor.SaveElementStep$1.next(SaveElementStep.java:37),0,0
1309,	at com.orientechnologies.orient.core.sql.executor.CountStep.syncPull(CountStep.java:53),0,0
1310,	at com.orientechnologies.orient.core.sql.executor.OSelectExecutionPlan.fetchNext(OSelectExecutionPlan.java:37),0,0
1311,	at com.orientechnologies.orient.core.sql.executor.OUpdateExecutionPlan.executeInternal(OUpdateExecutionPlan.java:46),0,0
1312,	at com.orientechnologies.orient.core.sql.parser.OUpdateStatement.execute(OUpdateStatement.java:144),0,0
1313,	at com.orientechnologies.orient.core.sql.parser.OStatement.execute(OStatement.java:59),0,0
1314,	at com.orientechnologies.orient.core.db.document.ODatabaseDocumentEmbedded.command(ODatabaseDocumentEmbedded.java:540),0,0
1315,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommand.executeStatement(OServerCommandPostCommand.java:175),0,0
1316,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommand.execute(OServerCommandPostCommand.java:84),0,0
1317,	at com.orientechnologies.orient.server.network.protocol.http.command.post.OServerCommandPostCommandGraph.execute(OServerCommandPostCommandGraph.java:36),0,0
1318,	at com.orientechnologies.orient.server.network.protocol.http.ONetworkProtocolHttpAbstract.service(ONetworkProtocolHttpAbstract.java:172),0,0
1319,	at com.orientechnologies.orient.server.network.protocol.http.ONetworkProtocolHttpAbstract.execute(ONetworkProtocolHttpAbstract.java:633)`,0,0
1320,## Steps to reproduce,1,1
1321,`create vertex v set name = 'a'; --> #9:0`,0,0
1322,`create vertex v set name = 'b'; --> #10:0`,0,1
1323,`create vertex v set name = 'c'; --> #11:0`,0,1
1324,`create edge  e  from #10:0 to #11:0; --> #17:0`,0,1
1325,`update edge e set out = (select from v where name = 'a' ) where  @rid = #17:0`,0,0
1326,Looks like query strings are missing from the models and all consumers and providers.,1,1
1327,If enable jackOptions and add some relations to entities app it was crashed during build,1,1
1328,`Caused by: java.lang.NullPointerException,0,0
1329,at io.requery.processor.Mirrors.namesEqual(Mirrors.java:159),0,0
1330,at io.requery.processor.Mirrors.implementsInterface(Mirrors.java:109),0,0
1331,at io.requery.processor.Mirrors.isInstance(Mirrors.java:91),0,0
1332,at io.requery.processor.AttributeMember.validateCollectionType(AttributeMember.java:202),0,0
1333,at io.requery.processor.AttributeMember.checkMemberType(AttributeMember.java:194),0,0
1334,at io.requery.processor.AttributeMember.process(AttributeMember.java:147),0,0
1335,at io.requery.processor.EntityType.lambda$process$5(EntityType.java:114),0,0
1336,at io.requery.processor.EntityType.process(EntityType.java:114),0,0
1337,at io.requery.processor.EntityProcessor.process(EntityProcessor.java:147),0,0
1338,at com.android.jack.eclipse.jdt.internal.compiler.apt.dispatch.RoundDispatcher.handleProcessor(RoundDispatcher.java:139),0,0
1339,`,0,0
1340,"When using the `createEventConsumer()` or `createTelementryConsumer()`methods on a `HonoClient`, the given `creationHandler` param should fail if the """"attach"""" on the link fails (i.e. """"detach"""" was received).",1,1
1341,**Input file: `Test.java`**,1,0
1342,``` java,0,0
1343,public class Test {,0,0
1344,public static void main(String... args) {,0,0
1345,},0,0
1346,},0,0
1347,```,0,0
1348,**Configuration file: `my_check.xml`**,1,1
1349,``` xml,0,0
1350,"<?xml version=""""1.0""""?>",0,0
1351,<!DOCTYPE module PUBLIC,0,0
1352,"          """"-//Puppy Crawl//DTD Check Configuration 1.3//EN""""",0,0
1353,"          """"http://www.puppycrawl.com/dtds/configuration_1_3.dtd"""">",0,0
1354,"<module name = """"Checker"""">",0,0
1355,"    <property name=""""charset"""" value=""""UTF-8""""/>",0,0
1356,"    <property name=""""severity"""" value=""""warning""""/>",0,0
1357,"    <module name=""""TreeWalker"""">",0,0
1358,"       <module name=""""UncommentedMain""""/>",0,0
1359,</module>,0,0
1360,</module>,0,0
1361,**Checkstyle 6.12.1 output**,1,1
1362,```,0,0
1363,andreiselkin@andreiselkin ~/Downloads/temp $ java -jar checkstyle-6.12.1-all.jar -c my_check.xml Test.java,0,0
1364,Starting audit...,0,1
1365,Audit done.,0,1
1366,```,0,0
1367,**Observations**,1,1
1368,- ES version 2.2.1,1,1
1369,"- If number of documents indexed is 2 , there is no error or issue",1,1
1370,"- With following recreation , I am seeing array_index_out_of_bounds_exception exception ",1,1
1371,```,0,0
1372,curl -XDELETE 'http://localhost:9200/vm/',0,0
1373,echo,0,0
1374,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1375,echo,0,0
1376,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm1"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1377,echo,0,0
1378,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm2"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1379,echo,0,0
1380,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm3"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1381,echo,0,0
1382,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm4"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1383,echo,0,0
1384,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm5"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1385,echo,0,0
1386,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm6"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1387,echo,0,0
1388,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm7"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1389,echo,0,0
1390,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm8"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1391,echo,0,0
1392,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm9"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1393,echo,0,0
1394,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm10"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1395,echo,0,0
1396,"curl -XPOST 'http://localhost:9200/vm/vm' -d '{ """"name"""" : """"vm11"""" , """"rank"""" : 2 , """"date"""" : 2000 }'",0,0
1397,echo,0,0
1398,curl -XPOST 'http://localhost:9200/vm/_refresh',0,0
1399,echo,0,0
1400,curl -XPOST 'http://localhost:9200/vm/vm/_search?pretty' -d '{,0,0
1401,"  """"size"""": 0,",0,0
1402,"  """"aggs"""": {",0,0
1403,"    """"keywords"""": {",0,0
1404,"      """"terms"""": {",0,0
1405,"        """"collect_mode"""": """"breadth_first"""",",0,0
1406,"        """"field"""": """"name"""",",0,0
1407,"        """"size"""": 1,",0,0
1408,"        """"order"""": {",0,0
1409,"          """"dateB>rankAvg"""": """"asc""""",0,0
1410,},0,0
1411,"      },",0,0
1412,"      """"aggs"""": {",0,0
1413,"        """"dateB"""": {",0,0
1414,"          """"filter"""": {",0,0
1415,"            """"term"""": {",0,0
1416,"              """"date"""": 2001",0,0
1417,},0,0
1418,"          },",0,0
1419,"          """"aggs"""": {",0,0
1420,"            """"rankAvg"""": {",0,0
1421,"              """"min"""": {",0,0
1422,"                """"field"""": """"rank"""",",0,0
1423,"                """"missing"""": 1000",0,0
1424,},0,0
1425,},0,0
1426,},0,0
1427,},0,0
1428,},0,0
1429,},0,0
1430,},0,0
1431,}',0,0
1432,```,0,0
1433,Response,1,0
1434,```,0,0
1435,{,0,0
1436,"  """"took"""" : 13,",0,0
1437,"  """"timed_out"""" : false,",0,0
1438,"  """"_shards"""" : {",0,0
1439,"    """"total"""" : 5,",0,0
1440,"    """"successful"""" : 3,",0,0
1441,"    """"failed"""" : 2,",0,0
1442,"    """"failures"""" : [ {",0,0
1443,"      """"shard"""" : 2,",0,0
1444,"      """"index"""" : """"vm"""",",0,0
1445,"      """"node"""" : """"xpPiHlvJQjSgYu-L10WJuA"""",",0,0
1446,"      """"reason"""" : {",0,0
1447,"        """"type"""" : """"array_index_out_of_bounds_exception"""",",0,0
1448,"        """"reason"""" : """"1""""",0,0
1449,},0,0
1450,} ],0,0
1451,"  },",0,0
1452,"  """"hits"""" : {",0,0
1453,"    """"total"""" : 2,",0,0
1454,"    """"max_score"""" : 0.0,",0,0
1455,"    """"hits"""" : [ ]",0,0
1456,"  },",0,0
1457,"  """"aggregations"""" : {",0,0
1458,"    """"keywords"""" : {",0,0
1459,"      """"doc_count_error_upper_bound"""" : 0,",0,0
1460,"      """"sum_other_doc_count"""" : 1,",0,0
1461,"      """"buckets"""" : [ {",0,0
1462,"        """"key"""" : """"vm10"""",",0,0
1463,"        """"doc_count"""" : 1,",0,0
1464,"        """"dateB"""" : {",0,0
1465,"          """"doc_count"""" : 0,",0,0
1466,"          """"rankAvg"""" : {",0,0
1467,"            """"value"""" : null",0,0
1468,},0,0
1469,},0,0
1470,} ],0,0
1471,},0,0
1472,},0,0
1473,},0,0
1474,```,0,0
1475,Logs emitted,1,0
1476,```,0,0
1477,"[2016-03-21 21:53:55,238][DEBUG][action.search.type       ] [Gertrude Yorkes] [vm][4], node[pkRBZKPTStiOaYYr4mH_-w], [P], v[2], s[STARTED], a[id=Tf6t7fTWRz-FSvU30ln-mA]: Failed to execute [org.elasticsearch.action.search.SearchRequest@a062c99] lastShard [true]",0,0
1478,RemoteTransportException[[Gertrude Yorkes][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ArrayIndexOutOfBoundsException[1];,0,0
1479,Caused by: java.lang.ArrayIndexOutOfBoundsException: 1,0,0
1480,at org.elasticsearch.common.util.BigArrays$DoubleArrayWrapper.get(BigArrays.java:260),0,0
1481,at org.elasticsearch.search.aggregations.metrics.min.MinAggregator.metric(MinAggregator.java:100),0,0
1482,at org.elasticsearch.search.aggregations.bucket.terms.InternalOrder$Aggregation$3.compare(InternalOrder.java:213),0,0
1483,at org.elasticsearch.search.aggregations.bucket.terms.InternalOrder$Aggregation$3.compare(InternalOrder.java:210),0,0
1484,at org.elasticsearch.search.aggregations.bucket.terms.InternalOrder$CompoundOrder$CompoundOrderComparator.compare(InternalOrder.java:280),0,0
1485,at org.elasticsearch.search.aggregations.bucket.terms.InternalOrder$CompoundOrder$CompoundOrderComparator.compare(InternalOrder.java:266),0,0
1486,at org.elasticsearch.search.aggregations.bucket.terms.support.BucketPriorityQueue.lessThan(BucketPriorityQueue.java:37),0,0
1487,at org.elasticsearch.search.aggregations.bucket.terms.support.BucketPriorityQueue.lessThan(BucketPriorityQueue.java:26),0,0
1488,at org.apache.lucene.util.PriorityQueue.upHeap(PriorityQueue.java:258),0,0
1489,at org.apache.lucene.util.PriorityQueue.add(PriorityQueue.java:135),0,0
1490,at org.apache.lucene.util.PriorityQueue.insertWithOverflow(PriorityQueue.java:151),0,0
1491,at org.elasticsearch.search.aggregations.bucket.terms.GlobalOrdinalsStringTermsAggregator.buildAggregation(GlobalOrdinalsStringTermsAggregator.java:176),0,0
1492,at org.elasticsearch.search.aggregations.AggregationPhase.execute(AggregationPhase.java:167),0,0
1493,at org.elasticsearch.search.query.QueryPhase.execute(QueryPhase.java:119),0,0
1494,at org.elasticsearch.search.SearchService.loadOrExecuteQueryPhase(SearchService.java:364),0,0
1495,at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:376),0,0
1496,at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:368),0,0
1497,at org.elasticsearch.search.action.SearchServiceTransportAction$SearchQueryTransportHandler.messageReceived(SearchServiceTransportAction.java:365),0,0
1498,at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:350),0,0
1499,at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37),0,0
1500,at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142),0,0
1501,at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617),0,0
1502,at java.lang.Thread.run(Thread.java:745),0,0
1503,```,0,0
1504,"Please provide the following information. The more we know about your system and use case, the more easily and likely we can help.",1,1
1505,### Description of the problem / feature request / question:,1,1
1506,Building Bazel from scratch failed.,1,1
1507,"### If possible, provide a minimal example to reproduce the problem:",1,1
1508,set PATH=C:\msys64\usr\bin;C:\jdk\bin;C:\python35;C:\python35\scripts;%PATH%,0,0
1509,set BAZEL_SH=C:/msys64/usr/bin/bash.exe,0,0
1510,set JAVA_HOME=C:\jdk,0,0
1511,set BAZEL_PYTHON=C:/python35/python.exe,0,0
1512,set BAZEL_VS=C:/Program Files (x86)/Microsoft Visual Studio/2017/Enterprise,0,1
1513,set JAVA_HOME=C:\jdk,0,0
1514,bash compile.sh,0,0
1515,### Environment info,1,1
1516,* Operating System:,1,1
1517,Windows 10,1,0
1518,* Bazel version (output of `bazel info release`):,1,1
1519,0.6.1,0,0
1520,###  Have you found anything relevant by searching the web?,1,1
1521,None,1,1
1522,"### Anything else, information or logs or outputs that would be helpful?",1,1
1523,Build log:,1,1
1524,```,0,0
1525,Building Bazel from scratch......**********************************************************************,0,1
1526,** Visual Studio 2017 Developer Command Prompt v15.4.0,0,0
1527,** Copyright (c) 2017 Microsoft Corporation,0,1
1528,**********************************************************************,0,0
1529,[vcvarsall.bat] Environment initialized for: 'x64',0,0
1530,Microsoft (R) C/C++ Optimizing Compiler Version 19.11.25547 for x64,0,1
1531,Copyright (C) Microsoft Corporation.  All rights reserved.,0,1
1532,file-jni.cc,0,0
1533,D:\os\bazel-0.6.1-dist\src\main\native\windows\file-jni.cc(25): fatal error C1083: Cannot open include file: 'src/main/native/windows/file.h': No such file or directory,0,1
1534,file.cc,0,0
1535,D:\os\bazel-0.6.1-dist\src\main\native\windows\file.cc(21): fatal error C1083: Cannot open include file: 'src/main/native/windows/file.h': No such file or directory,0,1
1536,jni-util.cc,0,0
1537,D:\os\bazel-0.6.1-dist\src\main\native\windows\jni-util.cc(20): fatal error C1083: Cannot open include file: 'src/main/native/windows/jni-util.h': No such file or directory,0,1
1538,processes-jni.cc,0,0
1539,D:\os\bazel-0.6.1-dist\src\main\native\windows\processes-jni.cc(26): fatal error C1083: Cannot open include file: 'src/main/native/windows/jni-util.h': No such file or directory,0,1
1540,util.cc,0,0
1541,D:\os\bazel-0.6.1-dist\src\main\native\windows\util.cc(24): fatal error C1083: Cannot open include file: 'src/main/native/windows/util.h': No such file or directory,0,1
1542,Generating Code...,0,1
1543,```,0,0
1544,"The content of generated """"windows_jni.bat"""" is something like:",1,1
1545,```bat,0,0
1546,@echo OFF,0,1
1547,"@call """"C:/Program Files (x86)/Microsoft Visual Studio/2017/Enterprise/VC/Auxiliary/Build/VCVARSALL.BAT"""" amd64",0,0
1548,@cd D:\os\bazel-0.6.1-dist,0,0
1549,@set TMP=D:\aaa,0,0
1550,@CL /O2 /EHsc /LD /Fe,0,0
1551,```,0,0
1552,"However, after invoking """"VCVARSALL.BAT"""", current working directory would be under C:\xxxx, so """"cd D:\xxxxx"""" doesn't take effect immediately.  you need to call """"D:"""" after that.",1,1
1553,1. Open an image,1,1
1554,2. Open menu,1,1
1555,3. Click Send/Share,1,1
1556,4. :boom:,1,1
1557,All works as expected if I click on the share icon in the file list next to the same image.,1,1
1558,### Issue description,1,1
1559,"I am calling player.getCurrentPosition() to store current position before onPause() is called. However, it sometimes returns 0 (when the video is paused) so the player starts from the beginning when the app resumes.",1,1
1560,### Reproduction steps,1,1
1561,1. Seek to somewhere in the middle of the video. (I am testing HLS streaming),1,1
1562,2. Pause the video,1,1
1563,"3. Press power to turn off the screen and then turn on the screen to resume back to the app. At onPause(),  player.getCurrentPosition() gets called.",1,1
1564,"4. Repeat step 3, until player.getCurrentPosition() returns 0 onPause().",1,1
1565,### Version of ExoPlayer being used,1,1
1566,ExoPlayer version: 2.3.1,1,1
1567,### Device(s) and version(s) of Android being used,1,1
1568,Multiple devices,1,0
1569,We should add basic class condition and at least a check on the application type there.,1,1
1570,The logs show,1,1
1571,```,0,0
1572,/worker-10.233.78.201-2-client/worker.log,0,0
1573,"INFO  2014-09-15 14:38:07,554 [Thread-0] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Initializing test expir ---------------------------",0,0
1574,id=expir,0,0
1575,"INFO  2014-09-15 14:38:08,720 [Thread-2] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.setup() ------------------------------------",0,0
1576,"INFO  2014-09-15 14:38:08,813 [Thread-2] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.setup() ---------------------------",0,0
1577,"INFO  2014-09-15 14:38:10,731 [Thread-3] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localWarmup() ------------------------------------",0,0
1578,"INFO  2014-09-15 14:38:10,731 [Thread-3] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localWarmup() ---------------------------",0,0
1579,"INFO  2014-09-15 14:38:13,745 [Thread-4] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.run() ------------------------------------",0,0
1580,"FATAL 2014-09-15 14:38:13,782 [Thread-4] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Failed to execute expir.run() ------------------------------------",0,0
1581,"INFO  2014-09-15 14:40:14,915 [Thread-0] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- expir.stop() ------------------------------------",0,0
1582,"INFO  2014-09-15 14:40:24,955 [Thread-5] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localVerify() ------------------------------------",0,0
1583,"INFO  2014-09-15 14:40:24,955 [Thread-5] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localVerify() ---------------------------",0,0
1584,"INFO  2014-09-15 14:40:28,971 [Thread-6] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localTeardown() ------------------------------------",0,0
1585,"INFO  2014-09-15 14:40:28,971 [Thread-6] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localTeardown() ---------------------------",0,0
1586,```,0,0
1587,```,0,0
1588,./worker-10.233.78.201-1-server/worker.log,0,0
1589,"INFO  2014-09-15 14:38:06,938 [Thread-0] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Initializing test expir ---------------------------",0,0
1590,id=expir,0,0
1591,"INFO  2014-09-15 14:38:08,079 [Thread-2] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.setup() ------------------------------------",0,0
1592,"INFO  2014-09-15 14:38:08,097 [Thread-2] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.setup() ---------------------------",0,0
1593,"INFO  2014-09-15 14:38:10,090 [Thread-3] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localWarmup() ------------------------------------",0,0
1594,"INFO  2014-09-15 14:38:10,090 [Thread-3] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localWarmup() ---------------------------",0,0
1595,"INFO  2014-09-15 14:38:12,098 [Thread-4] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.globalWarmup() ------------------------------------",0,0
1596,"INFO  2014-09-15 14:38:12,125 [Thread-4] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.globalWarmup() ---------------------------",0,0
1597,"INFO  2014-09-15 14:38:14,108 [Thread-5] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Skipping expir.run(); member is passive ------------------------------------",0,0
1598,"INFO  2014-09-15 14:40:14,281 [Thread-0] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- expir.stop() ------------------------------------",0,0
1599,"INFO  2014-09-15 14:40:17,300 [Thread-6] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.globalVerify() ------------------------------------",0,0
1600,"INFO  2014-09-15 14:40:19,312 [Thread-6] com.hazelcast.stabilizer.tests.icache.ExpiryTest: expir: Counter{putExpiry=0, putAsyncExpiry=0, getExpiry=0, getAsyncExpiry=0} from 0 worker Threads",0,0
1601,"INFO  2014-09-15 14:40:19,890 [Thread-6] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.globalVerify() ---------------------------",0,0
1602,"INFO  2014-09-15 14:40:24,323 [Thread-7] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localVerify() ------------------------------------",0,0
1603,"INFO  2014-09-15 14:40:24,323 [Thread-7] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localVerify() ---------------------------",0,0
1604,"INFO  2014-09-15 14:40:26,331 [Thread-8] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.globalTeardown() ------------------------------------",0,0
1605,"INFO  2014-09-15 14:40:26,331 [Thread-8] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.globalTeardown() ---------------------------",0,0
1606,"INFO  2014-09-15 14:40:29,363 [Thread-9] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Starting expir.localTeardown() ------------------------------------",0,0
1607,"INFO  2014-09-15 14:40:29,363 [Thread-9] com.hazelcast.stabilizer.worker.MemberWorker: --------------------------- Finished expir.localTeardown() ---------------------------",0,0
1608,```,0,0
1609,```,0,0
1610,"INFO  2014-09-15 14:40:19,312 [Thread-6] com.hazelcast.stabilizer.tests.icache.ExpiryTest: expir: Counter{putExpiry=0, putAsyncExpiry=0, getExpiry=0, getAsyncExpiry=0} from 0 worker Threads",0,0
1611,```,0,0
1612,While Stabilizer shows,1,1
1613,```,0,0
1614,INFO  14:38:06 Running time per test: 00d 00h 02m 00s,0,0
1615,INFO  14:38:06 Expected total testsuite time: 00d 00h 02m 00s,0,0
1616,INFO  14:38:06 Running 1 tests parallel,0,0
1617,INFO  14:38:06 --------------------------------------------------------------,0,0
1618,Running Test : expir,0,0
1619,TestCase{,0,0
1620,id=expir,0,0
1621,"    , class=com.hazelcast.stabilizer.tests.icache.ExpiryTest",0,0
1622,},0,0
1623,--------------------------------------------------------------,0,0
1624,INFO  14:38:06 expir expir Starting Test initialization,0,0
1625,INFO  14:38:07 expir Completed Test initialization,0,0
1626,INFO  14:38:07 expir Starting Test setup,0,0
1627,INFO  14:38:09 expir Completed Test setup,0,0
1628,INFO  14:38:09 expir Starting Test local warmup,0,0
1629,INFO  14:38:11 expir Completed Test local warmup,0,0
1630,INFO  14:38:11 expir Starting Test global warmup,0,0
1631,INFO  14:38:13 expir Completed Test global warmup,0,0
1632,INFO  14:38:13 expir Starting Test start,0,0
1633,INFO  14:38:14 expir Completed Test start,0,0
1634,INFO  14:38:14 expir Test will run for 00d 00h 02m 00s,0,0
1635,"INFO  14:38:44 expir Running 00d 00h 00m 30s, 25.00 percent complete",0,0
1636,"INFO  14:39:14 expir Running 00d 00h 01m 00s, 50.00 percent complete",0,0
1637,"INFO  14:39:44 expir Running 00d 00h 01m 30s, 75.00 percent complete",0,0
1638,"INFO  14:40:14 expir Running 00d 00h 02m 00s, 100.00 percent complete",0,0
1639,INFO  14:40:14 expir Test finished running,0,0
1640,INFO  14:40:14 expir Starting Test stop,0,0
1641,INFO  14:40:16 expir Completed Test stop,0,0
1642,INFO  14:40:17 expir Starting Test global verify,0,0
1643,INFO  14:40:18 expir Waiting for globalVerify completion: 00d 00h 00m 01s,0,0
1644,INFO  14:40:24 expir Completed Test global verify,0,0
1645,INFO  14:40:24 expir Starting Test local verify,0,0
1646,INFO  14:40:26 expir Completed Test local verify,0,0
1647,INFO  14:40:26 expir Starting Test global tear down,0,0
1648,INFO  14:40:27 expir Finished Test global tear down,0,0
1649,INFO  14:40:27 expir Starting Test local tear down,0,0
1650,INFO  14:40:29 expir Completed Test local tear down,0,0
1651,INFO  14:40:29 Terminating workers,0,0
1652,INFO  14:40:29 All workers have been terminated,0,0
1653,INFO  14:40:29 Starting cool down (10 sec),0,0
1654,INFO  14:40:39 Finished cool down,0,0
1655,INFO  14:40:39 Total running time: 152 seconds,0,0
1656,INFO  14:40:39 -----------------------------------------------------------------------------,0,0
1657,INFO  14:40:39 No failures have been detected!,0,1
1658,INFO  14:40:39 -----------------------------------------------------------------------------,0,0
1659,```,0,0
1660,"its actually the same issue as https://github.com/spring-projects/spring-boot/issues/5271, I think the fix didn't work.",1,1
1661,`Log4J2LoggingSystem` installs a filter that denies all and removes it in `Log4J2LoggingSystem#initialize` that is invoked in `ApplicationEnvironmentPreparedEvent`. but if an exception is raised during the preparation of the environment then the filter is not removed yet and the exception is lost. i got it when i had an exception in an `EnvironmentPostProcessor`.,1,1
1662,you can run `sample.actuator.log4j2.SampleActuatorLog4J2Application` with this `application.yml` under resources.,1,1
1663,```yml,0,0
1664,---,0,0
1665,spring:,0,1
1666,profiles:,0,1
1667,active: local,0,0
1668,---,0,0
1669,spring:,0,1
1670,profiles: local,0,0
1671,a=test,0,0
1672,```,0,0
1673,but change the code of `sample.actuator.log4j2.SampleActuatorLog4J2Application` to look like that:,1,1
1674,```java,0,0
1675,try {,0,0
1676,"	SpringApplication.run(SampleActuatorLog4J2Application.class, args);",0,0
1677,}catch (Throwable e){,0,0
1678,"	LoggerFactory.getLogger(SampleActuatorLog4J2Application.class).error(""""error """",e);",0,0
1679,},0,0
1680,```,0,0
1681,"this is actually how our code looks like, we don't always have a main class, we initialize contexts in various ways.",1,1
1682,the exception is not logged.,1,1
1683,only if i remove the filter the exception is logged:,1,1
1684,```java,0,0
1685,try {,0,0
1686,"	SpringApplication.run(SampleActuatorLog4J2Application.class, args);",0,0
1687,}catch (Throwable e){,0,0
1688,	try {,0,0
1689,		Filter filter = ((LoggerContext) LogManager.getContext(false)).getConfiguration().getFilter();,0,0
1690,		if (filter != null) {,0,0
1691,			((LoggerContext) LogManager.getContext(false)).getConfiguration().removeFilter(filter);,0,0
1692,		},0,0
1693,	}catch (Throwable t){,0,0
1694,	},0,0
1695,"	LoggerFactory.getLogger(SampleActuatorLog4J2Application.class).error(""""error """",e);",0,0
1696,},0,0
1697,```,0,0
1698,Thanks,1,1
1699,"I have a webapp that I've developed with Spring, CXF and Apache Camel. I've been developing it for several months, using Tomcat to run and test it. This week, I integrated Spring Boot to take advantage of its external configuration feature.",1,1
1700,"Now something strange is happening. If I run """"mvn spring-boot:run"""" and run my integration tests against it, everything works fine. The headers on my SOAP requests look as follows:",1,1
1701,```,0,0
1702,HTTP/1.1 200 OK,0,1
1703,Server: Apache-Coyote/1.1,0,0
1704,X-Application-Context: application,0,0
1705,X-Application-Context: application,0,0
1706,Content-Type: application/soap+xml;charset=UTF-8,0,0
1707,Content-Length: 333,0,0
1708,"Date: Wed, 30 Jul 2014 17:03:18 GMT",0,0
1709,"However, if I run the same application in Tomcat, it seems that something is removing the Content-\* headers.",1,1
1710,```,0,0
1711,HTTP/1.1 200 OK,0,1
1712,Server: Apache-Coyote/1.1,0,0
1713,X-Application-Context: application,0,0
1714,Transfer-Encoding: chunked,0,0
1715,"Date: Wed, 30 Jul 2014 17:01:09 GMT",0,0
1716,```,0,0
1717,This all worked fine before I integrated Spring Boot 1.1.4.,1,1
1718,"As I described in the title, I am trying to utilize Key Hash Tags to accumulate data on the same ClusterNode.",1,1
1719,I am using a Multimap and noticed the Key for the Lists/Sets are wrapped in the Key Hash Tags and so they may be placed on another Node.,1,1
1720,For example:,1,1
1721,"The MultiMap key is """"{multi.map}.some.key"""".",1,1
1722,"An entry in it would be saved in the List/Set """"{{multi.map}.some.key}:ADJ..."""".",1,1
1723,"So the Hash is not """"multi.map"""" but rather """"{multi.map"""".",1,1
1724,"For further information see the """"Key Hash Tag"""" section on https://redis.io/topics/cluster-spec",1,1
1725,"TimeBoundary and maxTime queries do not need to access and merge data from every segment in an interval, they only need information from the most and least recent segments.",1,1
1726,### Description of the problem / feature request:,1,1
1727,"I want to use bazel to build a go project using [rules_go](https://github.com/bazelbuild/rules_go), I have some external packages in my `WORKSPACE` file. Some of these packages are in github, golang.org, gopkg.in etc., which can be fetched from internet. The other packages are placed in internal network. However, because I'm in China, for fetching the external internet packages from github, golang.org, gopkg.in, I must set a HTTP_PROXY and HTTPS_PROXY for enjoying a high speed. But for fetching the packages in internal network, I must set NO_PROXY.",1,1
1728,"However, if I set the HTTP_PROXY, HTTPS_PROXY and NO_PROXY and execute `bazel build //...`, the external packages can be fetched but the internal packages cannot be fetched. Seems bazel doesn't respect NO_PROXY. I use `htop` and find that bazel will hang in ",1,1
1729,```,0,0
1730,/cache/dfb1ce1d07f3a35961571a3241719bc6/external/bazel_gazelle_go_repository_tools/bin/fetch_repo --dest /cache/dfb1ce1d07f3a35961571a3241719bc6/external/<internal_package_name> --rev 84535ec2d57a694b372ec5effa446098b2c2202f --importpath <internal_package_address>,0,0
1731,```,0,0
1732,"The interesting thing is that if I execute the command above directly in the terminal, it can be successfully executed and fetch the packages in the relative directory.",1,1
1733,"And if I unset HTTP_PROXY and HTTPS_PROXY, I can successfully fetch the internal packages by using bazel.",1,1
1734,### Feature requests: what underlying problem are you trying to solve with this feature?,1,1
1735,"I notice that while I set HTTP_PROXY, bazel will show a log about ",1,1
1736,```,0,0
1737,"WARNING: detected http_proxy set in env, setting no_proxy for localhost.",0,1
1738,```,0,0
1739,"I try to find it in the [sources](https://github.com/bazelbuild/bazel/blob/master/src/main/cpp/blaze.cc#L1425) and discover that it seems bazel will set NO_PROXY directly to `localhost,127.0.0.1,0:0:0:0:0:0:0:1,::1` regardless of the origin value of NO_PROXY while HTTP_PROXY exists. Than I change the code to make it respects the origin value of NO_PROXY and use bazel to build it.",1,1
1740,"However, using the bazel built by myself, it also not worked for me to respect NO_PROXY. It cannot fetch the internal packages yet. I also try to reference https://github.com/bazelbuild/bazel/pull/4307 and https://github.com/bazelbuild/bazel/issues/4299, but it seems not a solution for my problem.",1,1
1741,### What operating system are you running Bazel on?,1,1
1742,"I use bazel 0.17.2 in ubuntu 18.04 and 16.04, both have the same bug",1,1
1743,### What's the output of `bazel info release`?,1,1
1744,`release 0.17.2`,1,0
1745,"### If `bazel info release` returns """"development version"""" or """"(@non-git)"""", tell us how you built Bazel.",1,1
1746,"I try to change code like [this](https://github.com/weixiao-huang/bazel/commit/2269036e434a7177782e06590eee8495a08080e1), and use bazel to rebuild bazel",1,1
1747,```,0,0
1748,bazel build //src:bazel,0,0
1749,```,0,0
1750,but the problem still exists.,1,1
1751,###  Have you found anything relevant by searching the web?,1,1
1752,"I just find some issues in bazel's git, but it seems that they have few helps for my problem",1,1
1753,- https://github.com/bazelbuild/bazel/pull/4307,0,1
1754,- https://github.com/bazelbuild/bazel/issues/4299,0,1
1755,"During repository verification the master node writes a single test file into repository and then all data nodes try to read this file back. If this operation fails, the error message `store location [......] is not shared between node [the data node name] and the master node]`. The message can be very confusing in situation when there is only one node in the cluster and the error is caused by wrong S3 permissions. ",1,1
1756,Address like `192.168.234.129:7001@17001` should be converted to `192.168.234.129:7001`,1,1
1757,Kotlin static interface fields cause `NotNull not applicable to static or final member` error.,1,1
1758,```,0,0
1759,@Entity,0,0
1760,"interface Thing : Persistable, Observable, Parcelable {",0,0
1761,@get:Key @get:Generated,0,0
1762,var id : Int,0,0
1763,companion object {,0,0
1764,"        const val THING_CONSTANT = """"something""""",0,0
1765,},0,0
1766,},0,0
1767,```,0,0
1768,I haven't tried with Java.,1,1
1769,"For asynchronous tests, the expected start-time isn't available. So asynchronous tests can only make use of actual start-time, reintroducing the coordinated omission problem.",1,1
1770,So it should be possible to expose the intended start-time as argument.,1,1
1771,"Hey,",1,1
1772,When I set `setPingConnectionInterval` in the replicated servers configuration it's not propagated to underlying master slave configuration:,1,1
1773,```,0,0
1774,config.useReplicatedServers(),0,0
1775,.setPingConnectionInterval(1000),0,0
1776,.addNodeAddress(nodeAddresses.toArray(new String[0]));,0,0
1777,```,0,0
1778,My current understand that ReplicatedServersConfig is used to create MasterSlaveServersConfiguration In the MasterSlaveConnectionManager in https://github.com/redisson/redisson/blob/master/redisson/src/main/java/org/redisson/connection/MasterSlaveConnectionManager.java#L389.,1,1
1779,In this method setPingConnectionInterval is not copied and default value is used in MasterSlaveServersConfiguration.,1,1
1780,"Using Netty on a Java-VM running on IBM z/OS it occurs, that creating a unique channel-id leads to problems.",1,1
1781,"It seems to me, that this process bases at least on the MAC-Address of networking hardware.  On IBM z/OS this information is not available with the usual JAVA-methods in NetworkInterface.  Netty logs always a warning to System.err running on z/OS that it fell back to a random MAC.",1,1
1782,So I decided to use the VM-Option io.netty.machineId=xxxxxxxx to inject here a valid MAC-Address retrieved from non-java resources on z/OS.,1,1
1783,"**To my regrets it does not work. The problem is not platform-dependent, even with in a SUN-VM running on Windows it is not possible to use this option.** ",1,1
1784,"Probably the Regular Expression, used to check the input, is not correct.",1,1
1785,I would recommend to change the used RegExp,1,1
1786,"` private static final Pattern MACHINE_ID_PATTERN = Pattern.compile(""""^(?:[0-9a-fA-F][:-]?){6,8}$"""");`",0,0
1787,to an expression more like,1,1
1788,"`([0-9a-fA-F]{2}[:-]){5,7}[0-9a-fA-F]{2}`",0,0
1789,### Expected behavior,1,1
1790,DefaultChannelId allows to customize the used MACAddress via System.property.,1,1
1791,Using -Dio.netty.machineId=00-14-5E-5A-AF-77 as Java-VM-option should be accepted as valid MACAddress.,1,1
1792,### Actual behavior,1,1
1793,Netty rejects this MACAddress as malformed:,1,1
1794,"`Dez 14, 2016 2:10:49 PM io.netty.channel.DefaultChannelId <clinit>",0,0
1795,WARNING: -Dio.netty.machineId: 00-14-5E-5A-AF-77 (malformed),0,0
1796,"Dez 14, 2016 2:10:49 PM io.netty.handler.logging.LoggingHandler channelRegistered",0,0
1797,INFO: [id: 0xa9354b7b] REGISTERED,0,0
1798,"Dez 14, 2016 2:10:49 PM io.netty.handler.logging.LoggingHandler bind",0,0
1799,INFO: [id: 0xa9354b7b] BIND: 0.0.0.0/0.0.0.0:8007,0,0
1800,"Dez 14, 2016 2:10:49 PM io.netty.handler.logging.LoggingHandler channelActive",0,0
1801,"INFO: [id: 0xa9354b7b, L:/0:0:0:0:0:0:0:0:8007] ACTIVE`",0,0
1802,### Steps to reproduce,1,1
1803,"Start any Netty-using application (i.e. your sample io.netty.example.echo.EchoServer) with VM-option -Dio.netty.machineId=xxxxxxxx to overrule the standard MAC-Address ascertaining in MacAddressUtil.bestAvailableMac(), where xxxxxxx is any MAC-Address in standard (IEEE 802) format for printing MAC-48 addresses in human-friendly form.",1,1
1804,### Minimal yet complete reproducer code (or URL to code),1,1
1805,see above. Reproducible via VM-option,1,1
1806,### Netty version,1,1
1807,4.1.5,0,0
1808,### JVM version (e.g. `java -version`),1,1
1809,"java version """"1.8.0_111""""",0,1
1810,Java(TM) SE Runtime Environment (build 1.8.0_111-b14),0,1
1811,"Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)",0,0
1812,### OS version (e.g. `uname -a`),1,1
1813,Windows 7 Professional Service Pack 1,0,1
1814,`RqLengthAware` gives wrong information at `available()` call,1,1
1815,We miss to notify the ChannelFuture of the pendingWrite which is just in progress if the SSLEngine was closed. This means the the ChannelFutureListener will never get notifived in that case.,1,1
